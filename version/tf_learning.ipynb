{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'interface', 'computer'],\n",
      " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
      " ['eps', 'user', 'interface', 'system'],\n",
      " ['system', 'human', 'system', 'eps'],\n",
      " ['user', 'response', 'time'],\n",
      " ['trees'],\n",
      " ['graph', 'trees'],\n",
      " ['graph', 'minors', 'trees'],\n",
      " ['graph', 'minors', 'survey']]\n"
     ]
    }
   ],
   "source": [
    "# !pip install gensim\n",
    "import gensim\n",
    "import pprint\n",
    "text_corpus = [\"Human machine interface for lab abc computer applications\",\n",
    "             \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",\n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "             \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "             \"Graph minors A survey\"]\n",
    "# Create a set of frequent words\n",
    "stoplist = set('for a of the and to in'.split(' '))\n",
    "# Lowercase each document, split it by white space and filter out stopwords\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "         for document in text_corpus]\n",
    "\n",
    "# Count word frequencies\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "# Only keep words that appear more than once\n",
    "processed_corpus = [[token for token in text if frequency[token] > 1] for text in texts]\n",
    "pprint.pprint(processed_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "dictionary = corpora.Dictionary(processed_corpus)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computer': 0,\n",
      " 'eps': 8,\n",
      " 'graph': 10,\n",
      " 'human': 1,\n",
      " 'interface': 2,\n",
      " 'minors': 11,\n",
      " 'response': 3,\n",
      " 'survey': 4,\n",
      " 'system': 5,\n",
      " 'time': 6,\n",
      " 'trees': 9,\n",
      " 'user': 7}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1)]\n"
     ]
    }
   ],
   "source": [
    "new_doc = \"Human computer interaction\"\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
    "print(new_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1)],\n",
      " [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
      " [(2, 1), (5, 1), (7, 1), (8, 1)],\n",
      " [(1, 1), (5, 2), (8, 1)],\n",
      " [(3, 1), (6, 1), (7, 1)],\n",
      " [(9, 1)],\n",
      " [(9, 1), (10, 1)],\n",
      " [(9, 1), (10, 1), (11, 1)],\n",
      " [(4, 1), (10, 1), (11, 1)]]\n"
     ]
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(text) for text in processed_corpus]\n",
    "pprint.pprint(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, 0.5898341626740045), (11, 0.8075244024440723)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "\n",
    "# train the model\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "\n",
    "# transform the \"system minors\" string\n",
    "words = \"system minors\".lower().split()\n",
    "print(tfidf[dictionary.doc2bow(words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import similarities\n",
    "\n",
    "index = similarities.SparseMatrixSimilarity(tfidf[bow_corpus], num_features=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.0), (1, 0.32448703), (2, 0.41707572), (3, 0.7184812), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.0), (8, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "query_document = 'system engineering'.split()\n",
    "query_bow = dictionary.doc2bow(query_document)\n",
    "sims = index[tfidf[query_bow]]\n",
    "print(list(enumerate(sims)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.7184812\n",
      "2 0.41707572\n",
      "1 0.32448703\n",
      "0 0.0\n",
      "4 0.0\n",
      "5 0.0\n",
      "6 0.0\n",
      "7 0.0\n",
      "8 0.0\n"
     ]
    }
   ],
   "source": [
    "for document_number, score in sorted(enumerate(sims), key=lambda x: x[1], reverse=True):\n",
    "    print(document_number, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpora and Vector Spaces\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-03 02:02:02,769 : INFO : saving Dictionary object under ./deerwester.dict, separately None\n",
      "2020-06-03 02:02:02,771 : INFO : saved ./deerwester.dict\n"
     ]
    }
   ],
   "source": [
    "dictionary.save('./deerwester.dict')  # store the dictionary, for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec demo\n",
    "%reset -f\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-03 03:07:51,295 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-06-03 03:07:51,296 : INFO : built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "\n",
    "class MyCorpus(object):\n",
    "    \"\"\"An interator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        corpus_path = datapath('lee_background.cor')\n",
    "        for line in open(corpus_path):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-03 03:09:03,818 : INFO : collecting all words and their counts\n",
      "2020-06-03 03:09:03,820 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-06-03 03:09:03,928 : INFO : collected 6981 word types from a corpus of 58152 raw words and 300 sentences\n",
      "2020-06-03 03:09:03,930 : INFO : Loading a fresh vocabulary\n",
      "2020-06-03 03:09:03,939 : INFO : effective_min_count=5 retains 1750 unique words (25% of original 6981, drops 5231)\n",
      "2020-06-03 03:09:03,940 : INFO : effective_min_count=5 leaves 49335 word corpus (84% of original 58152, drops 8817)\n",
      "2020-06-03 03:09:03,948 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2020-06-03 03:09:03,950 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2020-06-03 03:09:03,950 : INFO : downsampling leaves estimated 35935 word corpus (72.8% of prior 49335)\n",
      "2020-06-03 03:09:03,955 : INFO : estimated required memory for 1750 words and 100 dimensions: 2275000 bytes\n",
      "2020-06-03 03:09:03,956 : INFO : resetting layer weights\n",
      "2020-06-03 03:09:04,309 : INFO : training model with 3 workers on 1750 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-03 03:09:04,445 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-03 03:09:04,455 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-03 03:09:04,458 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-03 03:09:04,459 : INFO : EPOCH - 1 : training on 58152 raw words (36013 effective words) took 0.1s, 244655 effective words/s\n",
      "2020-06-03 03:09:04,595 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-03 03:09:04,596 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-03 03:09:04,598 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-03 03:09:04,599 : INFO : EPOCH - 2 : training on 58152 raw words (35977 effective words) took 0.1s, 261654 effective words/s\n",
      "2020-06-03 03:09:04,731 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-03 03:09:04,745 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-03 03:09:04,747 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-03 03:09:04,748 : INFO : EPOCH - 3 : training on 58152 raw words (35934 effective words) took 0.1s, 243235 effective words/s\n",
      "2020-06-03 03:09:04,882 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-03 03:09:04,892 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-03 03:09:04,895 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-03 03:09:04,896 : INFO : EPOCH - 4 : training on 58152 raw words (35895 effective words) took 0.1s, 245159 effective words/s\n",
      "2020-06-03 03:09:05,027 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-03 03:09:05,040 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-03 03:09:05,043 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-03 03:09:05,044 : INFO : EPOCH - 5 : training on 58152 raw words (35966 effective words) took 0.1s, 246978 effective words/s\n",
      "2020-06-03 03:09:05,045 : INFO : training on a 290760 raw words (179785 effective words) took 0.7s, 244773 effective words/s\n"
     ]
    }
   ],
   "source": [
    "import gensim.models\n",
    "\n",
    "sentences = MyCorpus()\n",
    "model = gensim.models.Word2Vec(sentences=sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00269477, -0.02434526,  0.02238227,  0.02677673, -0.04741764,\n",
       "        0.01725792,  0.05955269,  0.06336463, -0.03325649, -0.00725   ,\n",
       "        0.02932971,  0.05322807,  0.10096155,  0.03138018,  0.02115   ,\n",
       "        0.00411769, -0.06382673, -0.02785617, -0.05525706, -0.0160682 ,\n",
       "        0.08101115,  0.02231089, -0.00064019, -0.00869474,  0.05844448,\n",
       "        0.04394283,  0.01022059, -0.0748246 ,  0.00326857, -0.0224652 ,\n",
       "        0.01952092, -0.02028982, -0.04886932,  0.03620696, -0.0093549 ,\n",
       "        0.0213713 , -0.03056756,  0.01152956,  0.00536874,  0.03019593,\n",
       "       -0.05655464,  0.0285409 , -0.01244486,  0.06834869,  0.00950526,\n",
       "       -0.04446067, -0.00166665,  0.00827059,  0.03045221,  0.03716309,\n",
       "        0.01514133,  0.0171531 ,  0.00722389, -0.01139333,  0.01037639,\n",
       "        0.02450302,  0.04309493,  0.01562723,  0.01096504,  0.06577818,\n",
       "        0.03011777,  0.01612068, -0.0269418 ,  0.00527515, -0.02746065,\n",
       "       -0.01505195,  0.03651873,  0.0569701 ,  0.01330653,  0.04978124,\n",
       "        0.00397585,  0.01906402, -0.00201131,  0.01426818, -0.00579408,\n",
       "       -0.00053182, -0.02199109,  0.00914152,  0.0017215 ,  0.01867334,\n",
       "        0.027829  ,  0.00454491,  0.03532225, -0.03559559,  0.00737729,\n",
       "       -0.00438835, -0.00511341, -0.00819746,  0.01927309,  0.00682269,\n",
       "        0.06309002, -0.04354078, -0.05288001, -0.02957972,  0.05235671,\n",
       "        0.01379403, -0.01767658, -0.03948193, -0.009223  , -0.00554421],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hundreds\n",
      "of\n",
      "people\n",
      "have\n",
      "been\n",
      "forced\n",
      "to\n",
      "their\n",
      "homes\n",
      "in\n"
     ]
    }
   ],
   "source": [
    "for i, word in enumerate(model.wv.vocab):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-03 03:27:45,766 : INFO : saving Word2Vec object under ./w2v_demo_model, separately None\n",
      "2020-06-03 03:27:45,767 : INFO : not storing attribute vectors_norm\n",
      "2020-06-03 03:27:45,769 : INFO : not storing attribute cum_table\n",
      "2020-06-03 03:27:45,794 : INFO : saved ./w2v_demo_model\n"
     ]
    }
   ],
   "source": [
    "model.save('./w2v_demo_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-03 03:29:10,789 : INFO : loading Word2Vec object from ./w2v_demo_model\n",
      "2020-06-03 03:29:10,806 : INFO : loading wv recursively from ./w2v_demo_model.wv.* with mmap=None\n",
      "2020-06-03 03:29:10,807 : INFO : setting ignored attribute vectors_norm to None\n",
      "2020-06-03 03:29:10,807 : INFO : loading vocabulary recursively from ./w2v_demo_model.vocabulary.* with mmap=None\n",
      "2020-06-03 03:29:10,808 : INFO : loading trainables recursively from ./w2v_demo_model.trainables.* with mmap=None\n",
      "2020-06-03 03:29:10,809 : INFO : setting ignored attribute cum_table to None\n",
      "2020-06-03 03:29:10,809 : INFO : loaded ./w2v_demo_model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.00269477, -0.02434526,  0.02238227,  0.02677673, -0.04741764,\n",
       "        0.01725792,  0.05955269,  0.06336463, -0.03325649, -0.00725   ,\n",
       "        0.02932971,  0.05322807,  0.10096155,  0.03138018,  0.02115   ,\n",
       "        0.00411769, -0.06382673, -0.02785617, -0.05525706, -0.0160682 ,\n",
       "        0.08101115,  0.02231089, -0.00064019, -0.00869474,  0.05844448,\n",
       "        0.04394283,  0.01022059, -0.0748246 ,  0.00326857, -0.0224652 ,\n",
       "        0.01952092, -0.02028982, -0.04886932,  0.03620696, -0.0093549 ,\n",
       "        0.0213713 , -0.03056756,  0.01152956,  0.00536874,  0.03019593,\n",
       "       -0.05655464,  0.0285409 , -0.01244486,  0.06834869,  0.00950526,\n",
       "       -0.04446067, -0.00166665,  0.00827059,  0.03045221,  0.03716309,\n",
       "        0.01514133,  0.0171531 ,  0.00722389, -0.01139333,  0.01037639,\n",
       "        0.02450302,  0.04309493,  0.01562723,  0.01096504,  0.06577818,\n",
       "        0.03011777,  0.01612068, -0.0269418 ,  0.00527515, -0.02746065,\n",
       "       -0.01505195,  0.03651873,  0.0569701 ,  0.01330653,  0.04978124,\n",
       "        0.00397585,  0.01906402, -0.00201131,  0.01426818, -0.00579408,\n",
       "       -0.00053182, -0.02199109,  0.00914152,  0.0017215 ,  0.01867334,\n",
       "        0.027829  ,  0.00454491,  0.03532225, -0.03559559,  0.00737729,\n",
       "       -0.00438835, -0.00511341, -0.00819746,  0.01927309,  0.00682269,\n",
       "        0.06309002, -0.04354078, -0.05288001, -0.02957972,  0.05235671,\n",
       "        0.01379403, -0.01767658, -0.03948193, -0.009223  , -0.00554421],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec.load('./w2v_demo_model')\n",
    "model.wv['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/ipykernel/__main__.py:1: DeprecationWarning: Call to deprecated `evaluate_word_pairs` (Method will be removed in 4.0.0, use self.wv.evaluate_word_pairs() instead).\n",
      "  if __name__ == '__main__':\n",
      "2020-06-03 03:45:44,656 : INFO : Pearson correlation coefficient against /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/gensim/test/test_data/wordsim353.tsv: 0.1056\n",
      "2020-06-03 03:45:44,657 : INFO : Spearman rank-order correlation coefficient against /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/gensim/test/test_data/wordsim353.tsv: 0.0841\n",
      "2020-06-03 03:45:44,658 : INFO : Pairs with unknown words ratio: 83.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.10556483612984553, 0.4221209027340719),\n",
       " SpearmanrResult(correlation=0.08411955187144943, pvalue=0.5228134629850876),\n",
       " 83.0028328611898)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_word_pairs(datapath('wordsim353.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-03 03:50:48,038 : INFO : collecting all words and their counts\n",
      "2020-06-03 03:50:48,039 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-06-03 03:50:48,040 : INFO : collected 13 word types from a corpus of 13 raw words and 1 sentences\n",
      "2020-06-03 03:50:48,040 : INFO : Updating model with new vocabulary\n",
      "2020-06-03 03:50:48,041 : INFO : New added 0 unique words (0% of original 13) and increased the count of 0 pre-existing words (0% of original 13)\n",
      "2020-06-03 03:50:48,041 : INFO : deleting the raw counts dictionary of 13 items\n",
      "2020-06-03 03:50:48,042 : INFO : sample=0.001 downsamples 0 most-common words\n",
      "2020-06-03 03:50:48,042 : INFO : downsampling leaves estimated 0 word corpus (0.0% of prior 0)\n",
      "2020-06-03 03:50:48,046 : INFO : estimated required memory for 1750 words and 100 dimensions: 2275000 bytes\n",
      "2020-06-03 03:50:48,048 : INFO : updating layer weights\n",
      "/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/ipykernel/__main__.py:6: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "2020-06-03 03:50:48,050 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-06-03 03:50:48,051 : INFO : training model with 3 workers on 1750 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-03 03:50:48,053 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-03 03:50:48,054 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-03 03:50:48,055 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-03 03:50:48,056 : INFO : EPOCH - 1 : training on 13 raw words (6 effective words) took 0.0s, 2012 effective words/s\n",
      "2020-06-03 03:50:48,059 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-03 03:50:48,060 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-03 03:50:48,061 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-03 03:50:48,061 : INFO : EPOCH - 2 : training on 13 raw words (4 effective words) took 0.0s, 1544 effective words/s\n",
      "2020-06-03 03:50:48,064 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-03 03:50:48,064 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-03 03:50:48,065 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-03 03:50:48,066 : INFO : EPOCH - 3 : training on 13 raw words (5 effective words) took 0.0s, 2083 effective words/s\n",
      "2020-06-03 03:50:48,068 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-03 03:50:48,068 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-03 03:50:48,069 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-03 03:50:48,069 : INFO : EPOCH - 4 : training on 13 raw words (5 effective words) took 0.0s, 2337 effective words/s\n",
      "2020-06-03 03:50:48,072 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-03 03:50:48,073 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-03 03:50:48,073 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-03 03:50:48,074 : INFO : EPOCH - 5 : training on 13 raw words (6 effective words) took 0.0s, 2903 effective words/s\n",
      "2020-06-03 03:50:48,074 : INFO : training on a 65 raw words (26 effective words) took 0.0s, 1140 effective words/s\n",
      "2020-06-03 03:50:48,075 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(26, 65)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_sentences = [\n",
    "    ['Advanced', 'users', 'can', 'load', 'a', 'model',\n",
    "     'and', 'continue', 'training', 'it', 'with', 'more', 'sentences']\n",
    "]\n",
    "model.build_vocab(more_sentences, update=True)\n",
    "model.train(more_sentences, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-03 03:54:09,002 : INFO : collecting all words and their counts\n",
      "2020-06-03 03:54:09,004 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-06-03 03:54:09,112 : INFO : collected 6981 word types from a corpus of 58152 raw words and 300 sentences\n",
      "2020-06-03 03:54:09,113 : INFO : Loading a fresh vocabulary\n",
      "2020-06-03 03:54:09,184 : INFO : effective_min_count=1 retains 6981 unique words (100% of original 6981, drops 0)\n",
      "2020-06-03 03:54:09,185 : INFO : effective_min_count=1 leaves 58152 word corpus (100% of original 58152, drops 0)\n",
      "2020-06-03 03:54:09,213 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2020-06-03 03:54:09,214 : INFO : sample=0.001 downsamples 43 most-common words\n",
      "2020-06-03 03:54:09,215 : INFO : downsampling leaves estimated 45723 word corpus (78.6% of prior 58152)\n",
      "2020-06-03 03:54:09,236 : INFO : estimated required memory for 6981 words and 100 dimensions: 9075300 bytes\n",
      "2020-06-03 03:54:09,237 : INFO : resetting layer weights\n",
      "2020-06-03 03:54:10,700 : INFO : training model with 12 workers on 6981 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-03 03:54:10,829 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-06-03 03:54:10,838 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-06-03 03:54:10,839 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-06-03 03:54:10,847 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-06-03 03:54:10,854 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-06-03 03:54:10,856 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-03 03:54:10,859 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-03 03:54:10,930 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-03 03:54:10,940 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-03 03:54:10,941 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-03 03:54:10,947 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-03 03:54:10,950 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-03 03:54:10,951 : INFO : EPOCH - 1 : training on 58152 raw words (45643 effective words) took 0.2s, 185017 effective words/s\n",
      "2020-06-03 03:54:11,058 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-06-03 03:54:11,063 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-06-03 03:54:11,073 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-06-03 03:54:11,078 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-06-03 03:54:11,084 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-06-03 03:54:11,085 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-03 03:54:11,130 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-03 03:54:11,172 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-03 03:54:11,177 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-03 03:54:11,179 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-03 03:54:11,180 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-03 03:54:11,182 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-03 03:54:11,182 : INFO : EPOCH - 2 : training on 58152 raw words (45637 effective words) took 0.2s, 200591 effective words/s\n",
      "2020-06-03 03:54:11,297 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-06-03 03:54:11,305 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-06-03 03:54:11,311 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-06-03 03:54:11,321 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-06-03 03:54:11,322 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-06-03 03:54:11,324 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-03 03:54:11,346 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-03 03:54:11,397 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-03 03:54:11,410 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-03 03:54:11,411 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-03 03:54:11,413 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-03 03:54:11,420 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-03 03:54:11,421 : INFO : EPOCH - 3 : training on 58152 raw words (45647 effective words) took 0.2s, 193929 effective words/s\n",
      "2020-06-03 03:54:11,528 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-06-03 03:54:11,540 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-06-03 03:54:11,549 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-06-03 03:54:11,550 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-06-03 03:54:11,556 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-06-03 03:54:11,557 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-03 03:54:11,584 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-03 03:54:11,638 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-03 03:54:11,644 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-03 03:54:11,647 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-03 03:54:11,651 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-03 03:54:11,653 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-03 03:54:11,654 : INFO : EPOCH - 4 : training on 58152 raw words (45710 effective words) took 0.2s, 199513 effective words/s\n",
      "2020-06-03 03:54:11,769 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-06-03 03:54:11,778 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-06-03 03:54:11,786 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-06-03 03:54:11,791 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-06-03 03:54:11,792 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-06-03 03:54:11,794 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-03 03:54:11,820 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-03 03:54:11,873 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-03 03:54:11,875 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-03 03:54:11,883 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-03 03:54:11,885 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-03 03:54:11,891 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-03 03:54:11,892 : INFO : EPOCH - 5 : training on 58152 raw words (45693 effective words) took 0.2s, 196096 effective words/s\n",
      "2020-06-03 03:54:11,893 : INFO : training on a 290760 raw words (228330 effective words) took 1.2s, 191644 effective words/s\n",
      "2020-06-03 03:54:11,893 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676889.1875\n"
     ]
    }
   ],
   "source": [
    "# instantiating and training the Word2Vec model\n",
    "model_with_loss = gensim.models.Word2Vec(\n",
    "    sentences,\n",
    "    min_count=1,\n",
    "    compute_loss=True,\n",
    "    workers=12,\n",
    "    hs=0,\n",
    "    sg=1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# getting the training loss value\n",
    "training_loss = model_with_loss.get_latest_training_loss()\n",
    "print(training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-03 03:57:21,033 : ERROR : caught non-fatal exception while trying to update gensim-data cache from 'https://raw.githubusercontent.com/RaRe-Technologies/gensim-data/master/list.json'; using local cache at '/home/tione/gensim-data/information.json' instead\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/urllib/request.py\", line 1318, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/http/client.py\", line 1239, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/http/client.py\", line 1285, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/http/client.py\", line 1234, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/http/client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/http/client.py\", line 964, in send\n",
      "    self.connect()\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/http/client.py\", line 1392, in connect\n",
      "    super().connect()\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/http/client.py\", line 936, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/socket.py\", line 724, in create_connection\n",
      "    raise err\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/socket.py\", line 713, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/gensim/downloader.py\", line 198, in _load_info\n",
      "    info_bytes = urlopen(url).read()\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/urllib/request.py\", line 223, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/urllib/request.py\", line 526, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/urllib/request.py\", line 544, in _open\n",
      "    '_open', req)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/urllib/request.py\", line 504, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/urllib/request.py\", line 1361, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/urllib/request.py\", line 1320, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno 111] Connection refused>\n",
      "2020-06-03 03:57:24,644 : ERROR : caught non-fatal exception while trying to update gensim-data cache from 'https://raw.githubusercontent.com/RaRe-Technologies/gensim-data/master/list.json'; using local cache at '/home/tione/gensim-data/information.json' instead\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/urllib/request.py\", line 1318, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/http/client.py\", line 1239, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/http/client.py\", line 1285, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/http/client.py\", line 1234, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/http/client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/http/client.py\", line 964, in send\n",
      "    self.connect()\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/http/client.py\", line 1392, in connect\n",
      "    super().connect()\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/http/client.py\", line 936, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/socket.py\", line 724, in create_connection\n",
      "    raise err\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/socket.py\", line 713, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/gensim/downloader.py\", line 198, in _load_info\n",
      "    info_bytes = urlopen(url).read()\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/urllib/request.py\", line 223, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/urllib/request.py\", line 526, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/urllib/request.py\", line 544, in _open\n",
      "    '_open', req)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/urllib/request.py\", line 504, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/urllib/request.py\", line 1361, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/urllib/request.py\", line 1320, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno 111] Connection refused>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 31.6/31.6MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-03 04:07:26,653 : ERROR : caught non-fatal exception while trying to update gensim-data cache from 'https://raw.githubusercontent.com/RaRe-Technologies/gensim-data/master/list.json'; using local cache at '/home/tione/gensim-data/information.json' instead\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/urllib/request.py\", line 1318, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/http/client.py\", line 1239, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/http/client.py\", line 1285, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/http/client.py\", line 1234, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/http/client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/http/client.py\", line 964, in send\n",
      "    self.connect()\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/http/client.py\", line 1392, in connect\n",
      "    super().connect()\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/http/client.py\", line 936, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/socket.py\", line 724, in create_connection\n",
      "    raise err\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/socket.py\", line 713, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/gensim/downloader.py\", line 198, in _load_info\n",
      "    info_bytes = urlopen(url).read()\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/urllib/request.py\", line 223, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/urllib/request.py\", line 526, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/urllib/request.py\", line 544, in _open\n",
      "    '_open', req)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/urllib/request.py\", line 504, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/urllib/request.py\", line 1361, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"/opt/conda/envs/tensorflow2_py3/lib/python3.6/urllib/request.py\", line 1320, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno 111] Connection refused>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-03 04:07:26,656 : INFO : text8 downloaded\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "import gensim.models.word2vec\n",
    "import gensim.downloader as api\n",
    "import smart_open\n",
    "\n",
    "\n",
    "def head(path, size):\n",
    "    with smart_open.open(path) as fin:\n",
    "        return io.StringIO(fin.read(size))\n",
    "\n",
    "\n",
    "def generate_input_data():\n",
    "    lee_path = datapath('lee_background.cor')\n",
    "    ls = gensim.models.word2vec.LineSentence(lee_path)\n",
    "    ls.name = '25kB'\n",
    "    yield ls\n",
    "\n",
    "    text8_path = api.load('text8').fn\n",
    "    labels = ('1MB', '10MB', '50MB', '100MB')\n",
    "    sizes = (1024 ** 2, 10 * 1024 ** 2, 50 * 1024 ** 2, 100 * 1024 ** 2)\n",
    "    for l, s in zip(labels, sizes):\n",
    "        ls = gensim.models.word2vec.LineSentence(head(text8_path, s))\n",
    "        ls.name = l\n",
    "        yield ls\n",
    "\n",
    "\n",
    "input_data = list(generate_input_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #0: {'train_data': '25kB', 'compute_loss': True, 'sg': 0, 'hs': 0, 'train_time_mean': 0.6586259206136068, 'train_time_std': 0.03622667899798521}\n",
      "Word2vec model #1: {'train_data': '25kB', 'compute_loss': False, 'sg': 0, 'hs': 0, 'train_time_mean': 0.6543711026509603, 'train_time_std': 0.01124924227606954}\n",
      "Word2vec model #2: {'train_data': '25kB', 'compute_loss': True, 'sg': 0, 'hs': 1, 'train_time_mean': 0.8261089324951172, 'train_time_std': 0.015550244165232914}\n",
      "Word2vec model #3: {'train_data': '25kB', 'compute_loss': False, 'sg': 0, 'hs': 1, 'train_time_mean': 0.8217370510101318, 'train_time_std': 0.012713353096740439}\n",
      "Word2vec model #4: {'train_data': '25kB', 'compute_loss': True, 'sg': 1, 'hs': 0, 'train_time_mean': 0.9065844217936198, 'train_time_std': 0.01439750488154397}\n",
      "Word2vec model #5: {'train_data': '25kB', 'compute_loss': False, 'sg': 1, 'hs': 0, 'train_time_mean': 0.9083569049835205, 'train_time_std': 0.035316131028825665}\n",
      "Word2vec model #6: {'train_data': '25kB', 'compute_loss': True, 'sg': 1, 'hs': 1, 'train_time_mean': 1.4017166296641033, 'train_time_std': 0.0348808965775171}\n",
      "Word2vec model #7: {'train_data': '25kB', 'compute_loss': False, 'sg': 1, 'hs': 1, 'train_time_mean': 1.4285967350006104, 'train_time_std': 0.031089466801307936}\n",
      "Word2vec model #8: {'train_data': '1MB', 'compute_loss': True, 'sg': 0, 'hs': 0, 'train_time_mean': 1.5720788637797039, 'train_time_std': 0.02502132449332841}\n",
      "Word2vec model #9: {'train_data': '1MB', 'compute_loss': False, 'sg': 0, 'hs': 0, 'train_time_mean': 1.5410632292429607, 'train_time_std': 0.01811303711892551}\n",
      "Word2vec model #10: {'train_data': '1MB', 'compute_loss': True, 'sg': 0, 'hs': 1, 'train_time_mean': 1.990476926167806, 'train_time_std': 0.026710144799352}\n",
      "Word2vec model #11: {'train_data': '1MB', 'compute_loss': False, 'sg': 0, 'hs': 1, 'train_time_mean': 1.9889918963114421, 'train_time_std': 0.04643115769599309}\n",
      "Word2vec model #12: {'train_data': '1MB', 'compute_loss': True, 'sg': 1, 'hs': 0, 'train_time_mean': 2.1780195236206055, 'train_time_std': 0.014650287324851397}\n",
      "Word2vec model #13: {'train_data': '1MB', 'compute_loss': False, 'sg': 1, 'hs': 0, 'train_time_mean': 2.136164903640747, 'train_time_std': 0.020735487505043428}\n",
      "Word2vec model #14: {'train_data': '1MB', 'compute_loss': True, 'sg': 1, 'hs': 1, 'train_time_mean': 3.6576242446899414, 'train_time_std': 0.1282139317018428}\n",
      "Word2vec model #15: {'train_data': '1MB', 'compute_loss': False, 'sg': 1, 'hs': 1, 'train_time_mean': 3.57489275932312, 'train_time_std': 0.05904620822388424}\n",
      "Word2vec model #16: {'train_data': '10MB', 'compute_loss': True, 'sg': 0, 'hs': 0, 'train_time_mean': 10.992756048838297, 'train_time_std': 0.039510797222869175}\n",
      "Word2vec model #17: {'train_data': '10MB', 'compute_loss': False, 'sg': 0, 'hs': 0, 'train_time_mean': 11.013871987660727, 'train_time_std': 0.04283828355804087}\n",
      "Word2vec model #18: {'train_data': '10MB', 'compute_loss': True, 'sg': 0, 'hs': 1, 'train_time_mean': 13.89970850944519, 'train_time_std': 0.047414387025044004}\n",
      "Word2vec model #19: {'train_data': '10MB', 'compute_loss': False, 'sg': 0, 'hs': 1, 'train_time_mean': 13.894446214040121, 'train_time_std': 0.06802086497352658}\n",
      "Word2vec model #20: {'train_data': '10MB', 'compute_loss': True, 'sg': 1, 'hs': 0, 'train_time_mean': 14.513616641362509, 'train_time_std': 0.10367101361097994}\n",
      "Word2vec model #21: {'train_data': '10MB', 'compute_loss': False, 'sg': 1, 'hs': 0, 'train_time_mean': 14.25407854715983, 'train_time_std': 0.0742619333112506}\n",
      "Word2vec model #22: {'train_data': '10MB', 'compute_loss': True, 'sg': 1, 'hs': 1, 'train_time_mean': 29.22667344411214, 'train_time_std': 0.39784566531548876}\n",
      "Word2vec model #23: {'train_data': '10MB', 'compute_loss': False, 'sg': 1, 'hs': 1, 'train_time_mean': 28.762419939041138, 'train_time_std': 0.07047551839801443}\n",
      "   train_data  compute_loss  sg  hs  train_time_mean  train_time_std\n",
      "4        25kB          True   1   0         0.906584        0.014398\n",
      "5        25kB         False   1   0         0.908357        0.035316\n",
      "6        25kB          True   1   1         1.401717        0.034881\n",
      "7        25kB         False   1   1         1.428597        0.031089\n",
      "0        25kB          True   0   0         0.658626        0.036227\n",
      "1        25kB         False   0   0         0.654371        0.011249\n",
      "2        25kB          True   0   1         0.826109        0.015550\n",
      "3        25kB         False   0   1         0.821737        0.012713\n",
      "12        1MB          True   1   0         2.178020        0.014650\n",
      "13        1MB         False   1   0         2.136165        0.020735\n",
      "14        1MB          True   1   1         3.657624        0.128214\n",
      "15        1MB         False   1   1         3.574893        0.059046\n",
      "8         1MB          True   0   0         1.572079        0.025021\n",
      "9         1MB         False   0   0         1.541063        0.018113\n",
      "10        1MB          True   0   1         1.990477        0.026710\n",
      "11        1MB         False   0   1         1.988992        0.046431\n",
      "20       10MB          True   1   0        14.513617        0.103671\n",
      "21       10MB         False   1   0        14.254079        0.074262\n",
      "22       10MB          True   1   1        29.226673        0.397846\n",
      "23       10MB         False   1   1        28.762420        0.070476\n",
      "16       10MB          True   0   0        10.992756        0.039511\n",
      "17       10MB         False   0   0        11.013872        0.042838\n",
      "18       10MB          True   0   1        13.899709        0.047414\n",
      "19       10MB         False   0   1        13.894446        0.068021\n"
     ]
    }
   ],
   "source": [
    "# Temporarily reduce logging verbosity\n",
    "logging.root.level = logging.ERROR\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_time_values = []\n",
    "seed_val = 42\n",
    "sg_values = [0, 1]\n",
    "hs_values = [0, 1]\n",
    "\n",
    "fast = True\n",
    "if fast:\n",
    "    input_data_subset = input_data[:3]\n",
    "else:\n",
    "    input_data_subset = input_data\n",
    "\n",
    "\n",
    "for data in input_data_subset:\n",
    "    for sg_val in sg_values:\n",
    "        for hs_val in hs_values:\n",
    "            for loss_flag in [True, False]:\n",
    "                time_taken_list = []\n",
    "                for i in range(3):\n",
    "                    start_time = time.time()\n",
    "                    w2v_model = gensim.models.Word2Vec(\n",
    "                        data,\n",
    "                        compute_loss=loss_flag,\n",
    "                        sg=sg_val,\n",
    "                        hs=hs_val,\n",
    "                        seed=seed_val,\n",
    "                        workers=12,\n",
    "                    )\n",
    "                    time_taken_list.append(time.time() - start_time)\n",
    "\n",
    "                time_taken_list = np.array(time_taken_list)\n",
    "                time_mean = np.mean(time_taken_list)\n",
    "                time_std = np.std(time_taken_list)\n",
    "\n",
    "                model_result = {\n",
    "                    'train_data': data.name,\n",
    "                    'compute_loss': loss_flag,\n",
    "                    'sg': sg_val,\n",
    "                    'hs': hs_val,\n",
    "                    'train_time_mean': time_mean,\n",
    "                    'train_time_std': time_std,\n",
    "                }\n",
    "                print(\"Word2vec model #%i: %s\" % (len(train_time_values), model_result))\n",
    "                train_time_values.append(model_result)\n",
    "\n",
    "train_times_table = pd.DataFrame(train_time_values)\n",
    "train_times_table = train_times_table.sort_values(\n",
    "    by=['train_data', 'sg', 'hs', 'compute_loss'],\n",
    "    ascending=[False, False, True, False],\n",
    ")\n",
    "print(train_times_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-03 06:18:22,595 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the [('australia', 0.9999100565910339), ('yesterday', 0.9998998641967773), ('an', 0.9998995065689087), ('on', 0.9998971223831177), ('his', 0.9998931884765625), ('up', 0.9998925924301147), ('world', 0.9998903274536133), ('their', 0.9998873472213745), ('also', 0.999887228012085), ('which', 0.9998868703842163)]\n",
      "to [('up', 0.9999508857727051), ('would', 0.9999493360519409), ('will', 0.9999490976333618), ('says', 0.9999411106109619), ('for', 0.9999390840530396), ('with', 0.9999386072158813), ('has', 0.9999384880065918), ('company', 0.9999381899833679), ('about', 0.999937891960144), ('could', 0.9999357461929321)]\n",
      "of [('in', 0.9999499320983887), ('at', 0.9999431371688843), ('by', 0.9999421834945679), ('after', 0.9999419450759888), ('australian', 0.9999417066574097), ('with', 0.9999417066574097), ('on', 0.9999412894248962), ('and', 0.9999366998672485), ('two', 0.9999355673789978), ('also', 0.9999325275421143)]\n"
     ]
    }
   ],
   "source": [
    "# re-enable logging\n",
    "logging.root.level = logging.INFO\n",
    "\n",
    "most_similars_precalc = {word : model.wv.most_similar(word) for word in model.wv.index2word}\n",
    "for i, (key, value) in enumerate(most_similars_precalc.items()):\n",
    "    if i == 3:\n",
    "        break\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "words = ['voted', 'few', 'their', 'around']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('national', 0.9988196492195129), ('victoria', 0.9987943172454834), ('old', 0.9987684488296509), ('hill', 0.9987670183181763), ('also', 0.9987571239471436), ('then', 0.9987561106681824), ('all', 0.9987560510635376), ('world', 0.998752236366272), ('israel', 0.9987504482269287), ('second', 0.9987483024597168)]\n",
      "[('at', 0.999677300453186), ('around', 0.9996689558029175), ('sydney', 0.9996559619903564), ('north', 0.999655544757843), ('not', 0.999650239944458), ('before', 0.9996500611305237), ('an', 0.9996490478515625), ('in', 0.9996485114097595), ('australian', 0.999646008014679), ('which', 0.9996452927589417)]\n",
      "[('with', 0.9999502897262573), ('and', 0.9999480843544006), ('his', 0.9999470710754395), ('which', 0.999945878982544), ('also', 0.9999457001686096), ('who', 0.9999422430992126), ('about', 0.9999409914016724), ('an', 0.9999402761459351), ('by', 0.9999399781227112), ('if', 0.9999396204948425)]\n",
      "[('and', 0.9999417066574097), ('for', 0.9999378323554993), ('by', 0.9999364614486694), ('over', 0.9999344944953918), ('from', 0.9999328851699829), ('has', 0.9999310970306396), ('says', 0.9999307990074158), ('after', 0.9999297857284546), ('into', 0.999929666519165), ('about', 0.9999290108680725)]\n",
      "0.007212400436401367\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for word in words:\n",
    "    result = model.wv.most_similar(word)\n",
    "    print(result)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('national', 0.9988196492195129), ('victoria', 0.9987943172454834), ('old', 0.9987684488296509), ('hill', 0.9987670183181763), ('also', 0.9987571239471436), ('then', 0.9987561106681824), ('all', 0.9987560510635376), ('world', 0.998752236366272), ('israel', 0.9987504482269287), ('second', 0.9987483024597168)]\n",
      "[('at', 0.999677300453186), ('around', 0.9996689558029175), ('sydney', 0.9996559619903564), ('north', 0.999655544757843), ('not', 0.999650239944458), ('before', 0.9996500611305237), ('an', 0.9996490478515625), ('in', 0.9996485114097595), ('australian', 0.999646008014679), ('which', 0.9996452927589417)]\n",
      "[('with', 0.9999502897262573), ('and', 0.9999480843544006), ('his', 0.9999470710754395), ('which', 0.999945878982544), ('also', 0.9999457001686096), ('who', 0.9999422430992126), ('about', 0.9999409914016724), ('an', 0.9999402761459351), ('by', 0.9999399781227112), ('if', 0.9999396204948425)]\n",
      "[('and', 0.9999417066574097), ('for', 0.9999378323554993), ('by', 0.9999364614486694), ('over', 0.9999344944953918), ('from', 0.9999328851699829), ('has', 0.9999310970306396), ('says', 0.9999307990074158), ('after', 0.9999297857284546), ('into', 0.999929666519165), ('about', 0.9999290108680725)]\n",
      "0.0003981590270996094\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for word in words:\n",
    "    if 'voted' in most_similars_precalc:\n",
    "        result = most_similars_precalc[word]\n",
    "        print(result)\n",
    "    else:\n",
    "        result = model.wv.most_similar(word)\n",
    "        most_similars_precalc[word] = result\n",
    "        print(result)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-03 06:32:22,126 : INFO : font search path ['/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf', '/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/afm', '/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/pdfcorefonts']\n",
      "2020-06-03 06:32:23,170 : INFO : generated new fontManager\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the Word Embeddings\n",
    "# !pip install plotly\n",
    "from sklearn.decomposition import IncrementalPCA    # inital reduction\n",
    "from sklearn.manifold import TSNE                   # final reduction\n",
    "import numpy as np                                  # array handling\n",
    "\n",
    "\n",
    "def reduce_dimensions(model):\n",
    "    num_dimensions = 2  # final num dimensions (2D, 3D, etc)\n",
    "\n",
    "    vectors = [] # positions in vector space\n",
    "    labels = [] # keep track of words to label our data again later\n",
    "    for word in model.wv.vocab:\n",
    "        vectors.append(model.wv[word])\n",
    "        labels.append(word)\n",
    "\n",
    "    # convert both lists into numpy vectors for reduction\n",
    "    vectors = np.asarray(vectors)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    # reduce using t-SNE\n",
    "    vectors = np.asarray(vectors)\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
    "    vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    x_vals = [v[0] for v in vectors]\n",
    "    y_vals = [v[1] for v in vectors]\n",
    "    return x_vals, y_vals, labels\n",
    "\n",
    "\n",
    "x_vals, y_vals, labels = reduce_dimensions(model)\n",
    "\n",
    "def plot_with_plotly(x_vals, y_vals, labels, plot_in_notebook=True):\n",
    "    from plotly.offline import init_notebook_mode, iplot, plot\n",
    "    import plotly.graph_objs as go\n",
    "\n",
    "    trace = go.Scatter(x=x_vals, y=y_vals, mode='text', text=labels)\n",
    "    data = [trace]\n",
    "\n",
    "    if plot_in_notebook:\n",
    "        init_notebook_mode(connected=True)\n",
    "        iplot(data, filename='word-embedding-plot')\n",
    "    else:\n",
    "        plot(data, filename='word-embedding-plot.html')\n",
    "\n",
    "\n",
    "def plot_with_matplotlib(x_vals, y_vals, labels):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import random\n",
    "\n",
    "    random.seed(0)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.scatter(x_vals, y_vals)\n",
    "\n",
    "    #\n",
    "    # Label randomly subsampled 25 data points\n",
    "    #\n",
    "    indices = list(range(len(labels)))\n",
    "    selected_indices = random.sample(indices, 25)\n",
    "    for i in selected_indices:\n",
    "        plt.annotate(labels[i], (x_vals[i], y_vals[i]))\n",
    "    plt.show()\n",
    "\n",
    "# try:\n",
    "#     get_ipython()\n",
    "# except Exception:\n",
    "#     plot_function = plot_with_matplotlib\n",
    "# else:\n",
    "#     plot_function = plot_with_plotly\n",
    "plot_function = plot_with_matplotlib\n",
    "\n",
    "plot_function(x_vals, y_vals, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "  # Create a simple model.\n",
    "  inputs = keras.Input(shape=(32,))\n",
    "  outputs = keras.layers.Dense(1)(inputs)\n",
    "  model = keras.Model(inputs, outputs)\n",
    "  model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "  return model\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128 samples\n",
      "128/128 [==============================] - 1s 6ms/sample - loss: 0.4592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb8880dee10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = np.random.random((128, 32))\n",
    "test_target = np.random.random((128, 1))\n",
    "model.fit(test_input, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: my_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reconstructed_model = keras.models.load_model('my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_array_equal(\n",
    "  model.predict(test_input),\n",
    "  reconstructed_model.predict(test_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.9197176e-01],\n",
       "       [ 5.3354502e-01],\n",
       "       [ 5.3221565e-01],\n",
       "       [-2.4643463e-01],\n",
       "       [ 2.9604721e-01],\n",
       "       [-1.7099570e-01],\n",
       "       [ 2.1050741e-01],\n",
       "       [ 6.4309746e-02],\n",
       "       [ 6.6867054e-01],\n",
       "       [ 1.1164248e+00],\n",
       "       [ 2.5894290e-01],\n",
       "       [-4.5113632e-01],\n",
       "       [ 3.9030150e-01],\n",
       "       [ 1.0314107e+00],\n",
       "       [-1.0560724e-01],\n",
       "       [ 2.3955140e-02],\n",
       "       [ 3.8627669e-01],\n",
       "       [ 5.2383876e-01],\n",
       "       [-3.2709050e-01],\n",
       "       [-4.2951077e-01],\n",
       "       [ 4.0141118e-01],\n",
       "       [ 1.5115704e-01],\n",
       "       [ 1.7143428e-01],\n",
       "       [-1.9378874e-01],\n",
       "       [ 2.8906655e-02],\n",
       "       [ 1.8324424e-01],\n",
       "       [ 2.2799170e-01],\n",
       "       [ 7.0667975e-02],\n",
       "       [-7.9695687e-02],\n",
       "       [ 6.4121252e-01],\n",
       "       [ 8.7026050e-03],\n",
       "       [-8.8156843e-01],\n",
       "       [ 2.2460826e-01],\n",
       "       [-2.7920315e-01],\n",
       "       [ 1.9006982e-01],\n",
       "       [ 5.0772643e-01],\n",
       "       [ 8.3085018e-01],\n",
       "       [ 9.5130503e-01],\n",
       "       [ 6.3061476e-02],\n",
       "       [ 3.1734544e-01],\n",
       "       [ 5.8688104e-01],\n",
       "       [ 5.8936530e-01],\n",
       "       [-5.0725695e-02],\n",
       "       [ 2.1798708e-01],\n",
       "       [-7.4452102e-01],\n",
       "       [ 2.4757157e-01],\n",
       "       [ 6.9952786e-01],\n",
       "       [ 3.1251696e-01],\n",
       "       [ 1.3447820e+00],\n",
       "       [-5.8573568e-01],\n",
       "       [ 5.2210635e-01],\n",
       "       [-6.4415246e-02],\n",
       "       [ 3.4258604e-01],\n",
       "       [-7.7004600e-01],\n",
       "       [-1.5614089e-01],\n",
       "       [ 2.8013328e-01],\n",
       "       [ 5.7309669e-01],\n",
       "       [ 3.3131582e-01],\n",
       "       [-2.5193852e-01],\n",
       "       [-3.2097623e-01],\n",
       "       [ 3.3489972e-01],\n",
       "       [ 1.2095902e-01],\n",
       "       [ 1.0262659e+00],\n",
       "       [ 2.8582407e-02],\n",
       "       [-1.2464891e-01],\n",
       "       [ 4.6828821e-01],\n",
       "       [ 4.7400689e-01],\n",
       "       [-2.6277536e-01],\n",
       "       [ 5.0824088e-01],\n",
       "       [ 5.2248245e-01],\n",
       "       [ 2.5884536e-01],\n",
       "       [-3.6347941e-01],\n",
       "       [ 4.0064800e-01],\n",
       "       [-5.4821008e-01],\n",
       "       [ 1.0406405e-01],\n",
       "       [-5.5018641e-02],\n",
       "       [ 3.9369985e-01],\n",
       "       [ 1.1062084e+00],\n",
       "       [ 1.6559090e-01],\n",
       "       [ 3.9948851e-02],\n",
       "       [-1.8540740e-01],\n",
       "       [ 4.3493852e-01],\n",
       "       [-4.5789313e-04],\n",
       "       [ 3.0165261e-01],\n",
       "       [ 3.8518065e-01],\n",
       "       [ 1.6363429e-01],\n",
       "       [-1.5989192e-02],\n",
       "       [ 3.0046278e-01],\n",
       "       [-5.5022484e-01],\n",
       "       [ 4.0687863e-02],\n",
       "       [ 8.8232589e-01],\n",
       "       [-8.5320818e-01],\n",
       "       [-4.8493975e-01],\n",
       "       [-8.3517820e-02],\n",
       "       [-8.7601729e-03],\n",
       "       [-4.5770884e-01],\n",
       "       [ 1.4604536e-01],\n",
       "       [ 4.0148219e-01],\n",
       "       [-3.9488310e-01],\n",
       "       [-1.9699115e-01],\n",
       "       [ 1.6909377e-01],\n",
       "       [ 1.0827736e+00],\n",
       "       [-1.0385160e-01],\n",
       "       [-2.6301432e-01],\n",
       "       [-2.0895731e-01],\n",
       "       [ 6.7685103e-01],\n",
       "       [ 3.0204582e-01],\n",
       "       [ 2.0918070e-01],\n",
       "       [-7.2073718e-03],\n",
       "       [ 3.2026523e-01],\n",
       "       [ 2.1991861e-01],\n",
       "       [ 1.3595808e-01],\n",
       "       [-4.0328756e-01],\n",
       "       [-5.7866973e-01],\n",
       "       [-7.3018235e-01],\n",
       "       [ 7.8209251e-02],\n",
       "       [ 9.1852427e-01],\n",
       "       [-3.0952692e-01],\n",
       "       [ 6.8335783e-01],\n",
       "       [-7.6238054e-01],\n",
       "       [ 2.3459159e-01],\n",
       "       [ 6.8841618e-01],\n",
       "       [ 7.9364359e-01],\n",
       "       [ 4.2110819e-01],\n",
       "       [-5.2947903e-01],\n",
       "       [ 5.0976324e-01],\n",
       "       [ 2.4607907e-01],\n",
       "       [-2.5352138e-01]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.9197176e-01],\n",
       "       [ 5.3354502e-01],\n",
       "       [ 5.3221565e-01],\n",
       "       [-2.4643463e-01],\n",
       "       [ 2.9604721e-01],\n",
       "       [-1.7099570e-01],\n",
       "       [ 2.1050741e-01],\n",
       "       [ 6.4309746e-02],\n",
       "       [ 6.6867054e-01],\n",
       "       [ 1.1164248e+00],\n",
       "       [ 2.5894290e-01],\n",
       "       [-4.5113632e-01],\n",
       "       [ 3.9030150e-01],\n",
       "       [ 1.0314107e+00],\n",
       "       [-1.0560724e-01],\n",
       "       [ 2.3955140e-02],\n",
       "       [ 3.8627669e-01],\n",
       "       [ 5.2383876e-01],\n",
       "       [-3.2709050e-01],\n",
       "       [-4.2951077e-01],\n",
       "       [ 4.0141118e-01],\n",
       "       [ 1.5115704e-01],\n",
       "       [ 1.7143428e-01],\n",
       "       [-1.9378874e-01],\n",
       "       [ 2.8906655e-02],\n",
       "       [ 1.8324424e-01],\n",
       "       [ 2.2799170e-01],\n",
       "       [ 7.0667975e-02],\n",
       "       [-7.9695687e-02],\n",
       "       [ 6.4121252e-01],\n",
       "       [ 8.7026050e-03],\n",
       "       [-8.8156843e-01],\n",
       "       [ 2.2460826e-01],\n",
       "       [-2.7920315e-01],\n",
       "       [ 1.9006982e-01],\n",
       "       [ 5.0772643e-01],\n",
       "       [ 8.3085018e-01],\n",
       "       [ 9.5130503e-01],\n",
       "       [ 6.3061476e-02],\n",
       "       [ 3.1734544e-01],\n",
       "       [ 5.8688104e-01],\n",
       "       [ 5.8936530e-01],\n",
       "       [-5.0725695e-02],\n",
       "       [ 2.1798708e-01],\n",
       "       [-7.4452102e-01],\n",
       "       [ 2.4757157e-01],\n",
       "       [ 6.9952786e-01],\n",
       "       [ 3.1251696e-01],\n",
       "       [ 1.3447820e+00],\n",
       "       [-5.8573568e-01],\n",
       "       [ 5.2210635e-01],\n",
       "       [-6.4415246e-02],\n",
       "       [ 3.4258604e-01],\n",
       "       [-7.7004600e-01],\n",
       "       [-1.5614089e-01],\n",
       "       [ 2.8013328e-01],\n",
       "       [ 5.7309669e-01],\n",
       "       [ 3.3131582e-01],\n",
       "       [-2.5193852e-01],\n",
       "       [-3.2097623e-01],\n",
       "       [ 3.3489972e-01],\n",
       "       [ 1.2095902e-01],\n",
       "       [ 1.0262659e+00],\n",
       "       [ 2.8582407e-02],\n",
       "       [-1.2464891e-01],\n",
       "       [ 4.6828821e-01],\n",
       "       [ 4.7400689e-01],\n",
       "       [-2.6277536e-01],\n",
       "       [ 5.0824088e-01],\n",
       "       [ 5.2248245e-01],\n",
       "       [ 2.5884536e-01],\n",
       "       [-3.6347941e-01],\n",
       "       [ 4.0064800e-01],\n",
       "       [-5.4821008e-01],\n",
       "       [ 1.0406405e-01],\n",
       "       [-5.5018641e-02],\n",
       "       [ 3.9369985e-01],\n",
       "       [ 1.1062084e+00],\n",
       "       [ 1.6559090e-01],\n",
       "       [ 3.9948851e-02],\n",
       "       [-1.8540740e-01],\n",
       "       [ 4.3493852e-01],\n",
       "       [-4.5789313e-04],\n",
       "       [ 3.0165261e-01],\n",
       "       [ 3.8518065e-01],\n",
       "       [ 1.6363429e-01],\n",
       "       [-1.5989192e-02],\n",
       "       [ 3.0046278e-01],\n",
       "       [-5.5022484e-01],\n",
       "       [ 4.0687863e-02],\n",
       "       [ 8.8232589e-01],\n",
       "       [-8.5320818e-01],\n",
       "       [-4.8493975e-01],\n",
       "       [-8.3517820e-02],\n",
       "       [-8.7601729e-03],\n",
       "       [-4.5770884e-01],\n",
       "       [ 1.4604536e-01],\n",
       "       [ 4.0148219e-01],\n",
       "       [-3.9488310e-01],\n",
       "       [-1.9699115e-01],\n",
       "       [ 1.6909377e-01],\n",
       "       [ 1.0827736e+00],\n",
       "       [-1.0385160e-01],\n",
       "       [-2.6301432e-01],\n",
       "       [-2.0895731e-01],\n",
       "       [ 6.7685103e-01],\n",
       "       [ 3.0204582e-01],\n",
       "       [ 2.0918070e-01],\n",
       "       [-7.2073718e-03],\n",
       "       [ 3.2026523e-01],\n",
       "       [ 2.1991861e-01],\n",
       "       [ 1.3595808e-01],\n",
       "       [-4.0328756e-01],\n",
       "       [-5.7866973e-01],\n",
       "       [-7.3018235e-01],\n",
       "       [ 7.8209251e-02],\n",
       "       [ 9.1852427e-01],\n",
       "       [-3.0952692e-01],\n",
       "       [ 6.8335783e-01],\n",
       "       [-7.6238054e-01],\n",
       "       [ 2.3459159e-01],\n",
       "       [ 6.8841618e-01],\n",
       "       [ 7.9364359e-01],\n",
       "       [ 4.2110819e-01],\n",
       "       [-5.2947903e-01],\n",
       "       [ 5.0976324e-01],\n",
       "       [ 2.4607907e-01],\n",
       "       [-2.5352138e-01]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_model.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_py3",
   "language": "python",
   "name": "conda_tensorflow2_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
