{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged=pd.read_csv('./train_merged.csv')\n",
    "df=train_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<900000x2481135 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 27608868 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy import sparse\n",
    "train_merged=pd.read_csv('./train_merged.csv')\n",
    "df=train_merged\n",
    "v = CountVectorizer(lowercase=False,tokenizer=lambda x:x)\n",
    "cur=df.groupby(\"user_id\")[\"creative_id\"].apply(list)\n",
    "v_fit = v.fit_transform(cur)\n",
    "display(v_fit)\n",
    "sparse.save_npz('./v_fit.npz', v_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "user_info=pd.read_csv('user_info.csv')\n",
    "user_info.astype(int)\n",
    "agg=pd.read_csv('agg.csv')\n",
    "agg.astype(int)\n",
    "v_fit=sparse.load_npz('v_fit.npz')\n",
    "num_train=int(user_info.shape[0]*0.8)\n",
    "y_train=user_info[\"gender\"].iloc[:num_train]\n",
    "y_test=user_info[\"gender\"].iloc[num_train:]\n",
    "X_train=sparse.csr_matrix(agg.iloc[:num_train])\n",
    "X_test=sparse.csr_matrix(agg.iloc[num_train:])\n",
    "X_train=sparse.hstack((v_fit[:num_train,:],X_train),dtype=float).tocsr()\n",
    "X_test=sparse.hstack((v_fit[num_train:,:],X_test),dtype=float).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<720000x2481149 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 32167131 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         1\n",
       "         ..\n",
       "719995    1\n",
       "719996    1\n",
       "719997    0\n",
       "719998    0\n",
       "719999    1\n",
       "Name: gender, Length: 720000, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<180000x2481149 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8041737 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "720000    0\n",
       "720001    0\n",
       "720002    0\n",
       "720003    0\n",
       "720004    0\n",
       "         ..\n",
       "899995    0\n",
       "899996    0\n",
       "899997    0\n",
       "899998    0\n",
       "899999    1\n",
       "Name: gender, Length: 180000, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "display(X_train,y_train)\n",
    "display(X_test,y_test)\n",
    "train_data = lgb.Dataset(X_train,y_train)\n",
    "# train_data.save_binary('CountVectorizer_gender.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "[1]\tcv_agg's auc: 0.500013 + 0.000564483\n",
      "[2]\tcv_agg's auc: 0.50014 + 0.000603008\n",
      "[3]\tcv_agg's auc: 0.499881 + 0.00082602\n",
      "[4]\tcv_agg's auc: 0.499795 + 0.00106572\n",
      "[5]\tcv_agg's auc: 0.590675 + 0.00161227\n",
      "[6]\tcv_agg's auc: 0.589431 + 0.00167528\n",
      "[7]\tcv_agg's auc: 0.593548 + 0.00184955\n",
      "[8]\tcv_agg's auc: 0.59284 + 0.00175801\n",
      "[9]\tcv_agg's auc: 0.59482 + 0.00177275\n",
      "[10]\tcv_agg's auc: 0.594363 + 0.00182287\n",
      "[11]\tcv_agg's auc: 0.593967 + 0.00177995\n",
      "[12]\tcv_agg's auc: 0.593582 + 0.00176067\n",
      "[13]\tcv_agg's auc: 0.595016 + 0.00201939\n",
      "[14]\tcv_agg's auc: 0.595776 + 0.00215367\n",
      "[15]\tcv_agg's auc: 0.596331 + 0.00212959\n",
      "[16]\tcv_agg's auc: 0.596574 + 0.00213386\n",
      "[17]\tcv_agg's auc: 0.59678 + 0.00213544\n",
      "[18]\tcv_agg's auc: 0.59654 + 0.00215957\n",
      "[19]\tcv_agg's auc: 0.596283 + 0.00215937\n",
      "[20]\tcv_agg's auc: 0.596127 + 0.0021388\n",
      "[21]\tcv_agg's auc: 0.595901 + 0.00205704\n",
      "[22]\tcv_agg's auc: 0.596007 + 0.00197206\n",
      "[23]\tcv_agg's auc: 0.595857 + 0.00198712\n",
      "[24]\tcv_agg's auc: 0.595677 + 0.00200571\n",
      "[25]\tcv_agg's auc: 0.595492 + 0.00193704\n",
      "[26]\tcv_agg's auc: 0.595653 + 0.0019216\n",
      "[27]\tcv_agg's auc: 0.595506 + 0.00195741\n",
      "[28]\tcv_agg's auc: 0.595364 + 0.00197132\n",
      "[29]\tcv_agg's auc: 0.595443 + 0.00188636\n",
      "[30]\tcv_agg's auc: 0.59532 + 0.00192469\n",
      "[31]\tcv_agg's auc: 0.595379 + 0.00194332\n",
      "[32]\tcv_agg's auc: 0.59548 + 0.00193264\n",
      "[33]\tcv_agg's auc: 0.595472 + 0.00195001\n",
      "[34]\tcv_agg's auc: 0.595404 + 0.00190709\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c97f83547dcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m cv_results = lgb.cv(\n\u001b[1;32m     20\u001b[0m     \u001b[0mlgb_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratified\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     early_stopping_rounds=50, verbose_eval=1, show_stdv=True, seed=0)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks, eval_train_metric)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                     \u001b[0mend_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m--> 564\u001b[0;31m         \u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_agg_cv_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_train_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mhandler_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboosters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m                 \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandler_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1974\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1975\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1977\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %reset -f\n",
    "import lightgbm as lgb\n",
    "lgb_params = {'num_leaves': 2**7-1,\n",
    "              'min_data_in_leaf': 25, \n",
    "              'objective':'binary',\n",
    "              'max_depth': -1,\n",
    "              'learning_rate': 0.1,\n",
    "              'boosting': 'gbdt',\n",
    "              'feature_fraction': 0.6,\n",
    "              'bagging_fraction': 0.9,\n",
    "              'bagging_seed': 11,\n",
    "              'metric': 'auc',\n",
    "              'seed':1024,\n",
    "              'nthread':10,\n",
    "             }\n",
    "# with open('lgb.txt', 'a') as f:\n",
    "#     f.write(str(lgb_params))\n",
    "print(\"start training\")\n",
    "cv_results = lgb.cv(\n",
    "    lgb_params, train_data, num_boost_round=1000, nfold=5, stratified=False, shuffle=True,\n",
    "    early_stopping_rounds=50, verbose_eval=1, show_stdv=True, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture cap --no-stderr\n",
    "# !pip install lightgbm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "features=[\"creative_id\",\"ad_id\",\"product_id\",\"product_category\",\"advertiser_id\",\"industry\",\"time\",\"click_times\"]\n",
    "\n",
    "df=train_merged.drop(columns=[\"age\",\"user_id\"])\n",
    "# convert {1,2} to binary value {0,1}\n",
    "df[\"gender\"]-=1\n",
    "# split train data into 2 parts (cross validation)\n",
    "train=df.sample(frac=0.8) #random state is a seed value\n",
    "test=df.drop(train.index)\n",
    "y_train=train.pop(\"gender\")\n",
    "X_train=train\n",
    "y_test=test.pop(\"gender\")\n",
    "X_test=test\n",
    "# display(X_train,y_train)\n",
    "# display(X_test,y_test)\n",
    "\n",
    "\n",
    "\n",
    "train_data = lgb.Dataset(X_train,y_train)\n",
    "train_data.save_binary('gender.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9d40cfbb2bb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m cv_results = lgb.cv(\n\u001b[1;32m     21\u001b[0m     \u001b[0mlgb_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratified\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     early_stopping_rounds=50, verbose_eval=10, show_stdv=True, seed=0)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# print('best num_boost_round:', len(cv_results['auc-mean']))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks, eval_train_metric)\u001b[0m\n\u001b[1;32m    563\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    564\u001b[0m         \u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_agg_cv_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_train_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mhandler_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboosters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m                 \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandler_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36meval_valid\u001b[0;34m(self, feval)\u001b[0m\n\u001b[1;32m   2185\u001b[0m             \u001b[0mList\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2186\u001b[0m         \"\"\"\n\u001b[0;32m-> 2187\u001b[0;31m         return [item for i in range_(1, self.__num_dataset)\n\u001b[0m\u001b[1;32m   2188\u001b[0m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[1;32m   2189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2186\u001b[0m         \"\"\"\n\u001b[1;32m   2187\u001b[0m         return [item for i in range_(1, self.__num_dataset)\n\u001b[0;32m-> 2188\u001b[0;31m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[0m\u001b[1;32m   2189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[0;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[1;32m   2645\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_out_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m                 result.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m   2648\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtmp_out_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_inner_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length of eval results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%capture cap --no-stderr\n",
    "%reset -f\n",
    "import lightgbm as lgb\n",
    "train_data = lgb.Dataset('CountVectorizer_gender.bin')\n",
    "lgb_params = {'num_leaves': 2**6-1,\n",
    "              'min_data_in_leaf': 25, \n",
    "              'objective':'binary',\n",
    "              'max_depth': -1,\n",
    "              'learning_rate': 0.1,\n",
    "              'boosting': 'gbdt',\n",
    "              'feature_fraction': 0.6,\n",
    "              'bagging_fraction': 0.9,\n",
    "              'bagging_seed': 11,\n",
    "              'metric': 'auc',\n",
    "              'seed':1024,\n",
    "              'nthread':10,\n",
    "             }\n",
    "# with open('lgb.txt', 'a') as f:\n",
    "#     f.write(str(lgb_params))\n",
    "print(\"start training\")\n",
    "cv_results = lgb.cv(\n",
    "    lgb_params, train_data, num_boost_round=1000, nfold=5, stratified=False, shuffle=True,\n",
    "    early_stopping_rounds=50, verbose_eval=1, show_stdv=True, seed=0)\n",
    "# print('best num_boost_round:', len(cv_results['auc-mean']))\n",
    "# print('best cv score:', cv_results['auc-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e37bbb9fca44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lgb.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    }
   ],
   "source": [
    "# with open('lgb.txt', 'w') as f:\n",
    "#     f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_merged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d20096c96fdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"creative_id\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ad_id\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"product_id\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"product_category\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"advertiser_id\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"industry\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"click_times\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_merged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gender\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"user_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# split train data into 2 parts (cross validation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#random state is a seed value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_merged' is not defined"
     ]
    }
   ],
   "source": [
    "# !pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "features=[\"creative_id\",\"ad_id\",\"product_id\",\"product_category\",\"advertiser_id\",\"industry\",\"time\",\"click_times\"]\n",
    "\n",
    "df=train_merged.drop(columns=[\"gender\",\"user_id\"])\n",
    "# split train data into 2 parts (cross validation)\n",
    "train=df.sample(frac=0.8) #random state is a seed value\n",
    "test=df.drop(train.index)\n",
    "y_train=train.pop(\"age\")\n",
    "X_train=train\n",
    "y_test=test.pop(\"age\")\n",
    "X_test=test\n",
    "# display(X_train,y_train)\n",
    "# display(X_test,y_test)\n",
    "train_data.save_binary('age.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import lightgbm as lgb\n",
    "train_data = lgb.Dataset('age.bin')\n",
    "params = {'num_leaves': 2**7-1,\n",
    "          'min_data_in_leaf': 25, \n",
    "          'objective':'regression_l2',\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.1,\n",
    "          'min_child_samples': 20,\n",
    "          'boosting': 'gbdt',\n",
    "          'feature_fraction': 0.6,\n",
    "          'bagging_fraction': 0.9,\n",
    "          'bagging_seed': 11,\n",
    "          'metric': 'mae',\n",
    "          'seed':1024,\n",
    "          'lambda_l1': 0.2,\n",
    "          'nthread':12,\n",
    "         }\n",
    "print(\"start training\")\n",
    "cv_results = lgb.cv(\n",
    "    params, train_data, num_boost_round=1000, nfold=5, stratified=False, shuffle=True,\n",
    "    early_stopping_rounds=50, verbose_eval=10, show_stdv=True, seed=0)\n",
    "print('best num_boost_round:', len(cv_results['mae-mean']))\n",
    "print('best cv score:', cv_results['mae-mean'])\n",
    "# bst = lgb.train(param, train_data, num_round,categorical_feature=features)\n",
    "# bst.save_model('test_model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train, y_train, free_raw_data=False)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train,free_raw_data=False)\n",
    "params = {\n",
    "          'boosting_type': 'gbdt',\n",
    "          'objective': 'binary',\n",
    "          'metric': 'auc',\n",
    "          'nthread':12,\n",
    "          'learning_rate':0.1\n",
    "          }\n",
    " \n",
    "### 交叉验证(调参)\n",
    "print('交叉验证')\n",
    "max_auc = float('0')\n",
    "best_params = {}\n",
    " \n",
    "# 准确率\n",
    "print(\"调参1：提高准确率\")\n",
    "for num_leaves in range(5,100,5):\n",
    "    for max_depth in range(3,8,1):\n",
    "        params['num_leaves'] = num_leaves\n",
    "        params['max_depth'] = max_depth\n",
    " \n",
    "        cv_results = lgb.cv(\n",
    "                            params,\n",
    "                            lgb_train,\n",
    "                            seed=1,\n",
    "                            nfold=5,\n",
    "                            metrics=['auc'],\n",
    "                            early_stopping_rounds=10,\n",
    "                            verbose_eval=True\n",
    "                            )\n",
    "            \n",
    "        mean_auc = pd.Series(cv_results['auc-mean']).max()\n",
    "        boost_rounds = pd.Series(cv_results['auc-mean']).idxmax()\n",
    "            \n",
    "        if mean_auc >= max_auc:\n",
    "            max_auc = mean_auc\n",
    "            best_params['num_leaves'] = num_leaves\n",
    "            best_params['max_depth'] = max_depth\n",
    "if 'num_leaves' and 'max_depth' in best_params.keys():          \n",
    "    params['num_leaves'] = best_params['num_leaves']\n",
    "    params['max_depth'] = best_params['max_depth']\n",
    " \n",
    "# 过拟合\n",
    "print(\"调参2：降低过拟合\")\n",
    "for max_bin in range(5,256,10):\n",
    "    for min_data_in_leaf in range(1,102,10):\n",
    "            params['max_bin'] = max_bin\n",
    "            params['min_data_in_leaf'] = min_data_in_leaf\n",
    "            \n",
    "            cv_results = lgb.cv(\n",
    "                                params,\n",
    "                                lgb_train,\n",
    "                                seed=1,\n",
    "                                nfold=5,\n",
    "                                metrics=['auc'],\n",
    "                                early_stopping_rounds=10,\n",
    "                                verbose_eval=True\n",
    "                                )\n",
    "                    \n",
    "            mean_auc = pd.Series(cv_results['auc-mean']).max()\n",
    "            boost_rounds = pd.Series(cv_results['auc-mean']).idxmax()\n",
    " \n",
    "            if mean_auc >= max_auc:\n",
    "                max_auc = mean_auc\n",
    "                best_params['max_bin']= max_bin\n",
    "                best_params['min_data_in_leaf'] = min_data_in_leaf\n",
    "if 'max_bin' and 'min_data_in_leaf' in best_params.keys():\n",
    "    params['min_data_in_leaf'] = best_params['min_data_in_leaf']\n",
    "    params['max_bin'] = best_params['max_bin']\n",
    " \n",
    "print(\"调参3：降低过拟合\")\n",
    "for feature_fraction in [0.6,0.7,0.8,0.9,1.0]:\n",
    "    for bagging_fraction in [0.6,0.7,0.8,0.9,1.0]:\n",
    "        for bagging_freq in range(0,50,5):\n",
    "            params['feature_fraction'] = feature_fraction\n",
    "            params['bagging_fraction'] = bagging_fraction\n",
    "            params['bagging_freq'] = bagging_freq\n",
    "            \n",
    "            cv_results = lgb.cv(\n",
    "                                params,\n",
    "                                lgb_train,\n",
    "                                seed=1,\n",
    "                                nfold=5,\n",
    "                                metrics=['auc'],\n",
    "                                early_stopping_rounds=10,\n",
    "                                verbose_eval=True\n",
    "                                )\n",
    "                    \n",
    "            mean_auc = pd.Series(cv_results['auc-mean']).max()\n",
    "            boost_rounds = pd.Series(cv_results['auc-mean']).idxmax()\n",
    " \n",
    "            if mean_auc >= max_auc:\n",
    "                max_auc=mean_auc\n",
    "                best_params['feature_fraction'] = feature_fraction\n",
    "                best_params['bagging_fraction'] = bagging_fraction\n",
    "                best_params['bagging_freq'] = bagging_freq\n",
    " \n",
    "if 'feature_fraction' and 'bagging_fraction' and 'bagging_freq' in best_params.keys():\n",
    "    params['feature_fraction'] = best_params['feature_fraction']\n",
    "    params['bagging_fraction'] = best_params['bagging_fraction']\n",
    "    params['bagging_freq'] = best_params['bagging_freq']\n",
    " \n",
    " \n",
    "print(\"调参4：降低过拟合\")\n",
    "for lambda_l1 in [1e-5,1e-3,1e-1,0.0,0.1,0.3,0.5,0.7,0.9,1.0]:\n",
    "    for lambda_l2 in [1e-5,1e-3,1e-1,0.0,0.1,0.4,0.6,0.7,0.9,1.0]:\n",
    "        params['lambda_l1'] = lambda_l1\n",
    "        params['lambda_l2'] = lambda_l2\n",
    "        cv_results = lgb.cv(\n",
    "                            params,\n",
    "                            lgb_train,\n",
    "                            seed=1,\n",
    "                            nfold=5,\n",
    "                            metrics=['auc'],\n",
    "                            early_stopping_rounds=10,\n",
    "                            verbose_eval=True\n",
    "                            )\n",
    "                \n",
    "        mean_auc = pd.Series(cv_results['auc-mean']).max()\n",
    "        boost_rounds = pd.Series(cv_results['auc-mean']).idxmax()\n",
    " \n",
    "        if mean_auc >= max_auc:\n",
    "            max_auc=mean_auc\n",
    "            best_params['lambda_l1'] = lambda_l1\n",
    "            best_params['lambda_l2'] = lambda_l2\n",
    "if 'lambda_l1' and 'lambda_l2' in best_params.keys():\n",
    "    params['lambda_l1'] = best_params['lambda_l1']\n",
    "    params['lambda_l2'] = best_params['lambda_l2']\n",
    " \n",
    "print(\"调参5：降低过拟合2\")\n",
    "for min_split_gain in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "    params['min_split_gain'] = min_split_gain\n",
    "    \n",
    "    cv_results = lgb.cv(\n",
    "                        params,\n",
    "                        lgb_train,\n",
    "                        seed=1,\n",
    "                        nfold=5,\n",
    "                        metrics=['auc'],\n",
    "                        early_stopping_rounds=10,\n",
    "                        verbose_eval=True\n",
    "                        )\n",
    "            \n",
    "    mean_auc = pd.Series(cv_results['auc-mean']).max()\n",
    "    boost_rounds = pd.Series(cv_results['auc-mean']).idxmax()\n",
    " \n",
    "    if mean_auc >= max_auc:\n",
    "        max_auc=mean_auc\n",
    "        \n",
    "        best_params['min_split_gain'] = min_split_gain\n",
    "if 'min_split_gain' in best_params.keys():\n",
    "    params['min_split_gain'] = best_params['min_split_gain']\n",
    " \n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "df=tmpdf\n",
    "features=[\"creative_id\"]\n",
    "v = TfidfVectorizer(max_df=1.0,min_df=1,lowercase=False,tokenizer=lambda x:x)\n",
    "for feature in features:\n",
    "    cur=df.groupby(\"user_id\")[feature].apply(list)\n",
    "    v_fit = v.fit_transform(cur)\n",
    "    word=v.get_feature_names()\n",
    "    display(v_fit)\n",
    "    display(type(v_fit))\n",
    "#     for i in range(len(weight)):\n",
    "#         print(\"-----output feature={}, user_id={} tf-idf-----\".format(feature,i+1))\n",
    "#         for j in range(len(word)):\n",
    "#             print(word[j],weight[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_py3",
   "language": "python",
   "name": "conda_tensorflow2_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
