{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ad=pd.read_csv(\"../test/ad.csv\")\n",
    "# test_click_log=pd.read_csv(\"../test/click_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ad=pd.read_csv(\"../train_preliminary/ad.csv\")\n",
    "train_click_log=pd.read_csv(\"../train_preliminary/click_log.csv\")\n",
    "train_user=pd.read_csv(\"../train_preliminary/user.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged=pd.merge(train_ad,train_click_log,on='creative_id')\n",
    "train_merged=pd.merge(train_merged,train_user,on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_merged.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot compare types 'ndarray(dtype=int64)' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-94a45e20397a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_merged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"product_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"\\\\N\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_merged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"industry\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"\\\\N\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_merged\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_merged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_merged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_merged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_merged.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   4176\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4177\u001b[0m             \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4178\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4179\u001b[0m         )\n\u001b[1;32m   4180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   6644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6645\u001b[0m             return self.replace(\n\u001b[0;32m-> 6646\u001b[0;31m                 \u001b[0mto_replace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6647\u001b[0m             )\n\u001b[1;32m   6648\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   4176\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4177\u001b[0m             \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4178\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4179\u001b[0m         )\n\u001b[1;32m   4180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   6697\u001b[0m                         \u001b[0mdest_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6698\u001b[0m                         \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6699\u001b[0;31m                         \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6700\u001b[0m                     )\n\u001b[1;32m   6701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreplace_list\u001b[0;34m(self, src_list, dest_list, inplace, regex)\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_compare_or_regex_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_compare_or_regex_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcomp\u001b[0;34m(s, regex)\u001b[0m\n\u001b[1;32m    609\u001b[0m                     \u001b[0mmaybe_convert_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masm8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m                 )\n\u001b[0;32m--> 611\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_compare_or_regex_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_compare_or_regex_search\u001b[0;34m(a, b, regex)\u001b[0m\n\u001b[1;32m   1934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1935\u001b[0m         raise TypeError(\n\u001b[0;32m-> 1936\u001b[0;31m             \u001b[0;34mf\"Cannot compare types {repr(type_names[0])} and {repr(type_names[1])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1937\u001b[0m         )\n\u001b[1;32m   1938\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot compare types 'ndarray(dtype=int64)' and 'str'"
     ]
    }
   ],
   "source": [
    "train_merged[\"product_id\"].replace({\"\\\\N\":\"0\"},inplace=True)\n",
    "train_merged[\"industry\"].replace({\"\\\\N\":\"0\"},inplace=True)\n",
    "train_merged=train_merged.astype(int)\n",
    "display(train_merged)\n",
    "del train_ad,train_click_log,train_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged.to_csv(\"train_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[\"creative_id\",\"ad_id\",\"product_id\",\"product_category\",\"advertiser_id\",\"industry\",\"time\",\"click_times\"]\n",
    "targets=[\"age\",\"gender\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmpdf=train_merged.sample(frac=0.1)\n",
    "# tmpdf.info()\n",
    "# display(tmpdf)\n",
    "# tmpdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Dataset at 0x7f6e3c1434e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%capture cap --no-stderr\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "features=[\"creative_id\",\"ad_id\",\"product_id\",\"product_category\",\"advertiser_id\",\"industry\",\"time\",\"click_times\"]\n",
    "\n",
    "df=train_merged.drop(columns=[\"age\",\"user_id\"])\n",
    "# convert {1,2} to binary value {0,1}\n",
    "df[\"gender\"]-=1\n",
    "# split train data into 2 parts (cross validation)\n",
    "train=df.sample(frac=0.8) #random state is a seed value\n",
    "test=df.drop(train.index)\n",
    "y_train=train.pop(\"gender\")\n",
    "X_train=train\n",
    "y_test=test.pop(\"gender\")\n",
    "X_test=test\n",
    "# display(X_train,y_train)\n",
    "# display(X_test,y_test)\n",
    "\n",
    "\n",
    "train_data = lgb.Dataset(X_train,y_train)\n",
    "train_data.save_binary('gender.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9d40cfbb2bb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m cv_results = lgb.cv(\n\u001b[1;32m     21\u001b[0m     \u001b[0mlgb_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratified\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     early_stopping_rounds=50, verbose_eval=10, show_stdv=True, seed=0)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# print('best num_boost_round:', len(cv_results['auc-mean']))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks, eval_train_metric)\u001b[0m\n\u001b[1;32m    563\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    564\u001b[0m         \u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_agg_cv_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_train_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mhandler_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboosters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m                 \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandler_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36meval_valid\u001b[0;34m(self, feval)\u001b[0m\n\u001b[1;32m   2185\u001b[0m             \u001b[0mList\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2186\u001b[0m         \"\"\"\n\u001b[0;32m-> 2187\u001b[0;31m         return [item for i in range_(1, self.__num_dataset)\n\u001b[0m\u001b[1;32m   2188\u001b[0m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[1;32m   2189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2186\u001b[0m         \"\"\"\n\u001b[1;32m   2187\u001b[0m         return [item for i in range_(1, self.__num_dataset)\n\u001b[0;32m-> 2188\u001b[0;31m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[0m\u001b[1;32m   2189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[0;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[1;32m   2645\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_out_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m                 result.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m   2648\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtmp_out_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_inner_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length of eval results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%capture cap --no-stderr\n",
    "%reset -f\n",
    "import lightgbm as lgb\n",
    "train_data = lgb.Dataset('train.bin')\n",
    "lgb_params = {'num_leaves': 2**6-1,\n",
    "              'min_data_in_leaf': 25, \n",
    "              'objective':'binary',\n",
    "              'max_depth': -1,\n",
    "              'learning_rate': 0.1,\n",
    "              'boosting': 'gbdt',\n",
    "              'feature_fraction': 0.6,\n",
    "              'bagging_fraction': 0.9,\n",
    "              'bagging_seed': 11,\n",
    "              'metric': 'auc',\n",
    "              'seed':1024,\n",
    "              'nthread':10,\n",
    "             }\n",
    "# with open('lgb.txt', 'a') as f:\n",
    "#     f.write(str(lgb_params))\n",
    "print(\"start training\")\n",
    "cv_results = lgb.cv(\n",
    "    lgb_params, train_data, num_boost_round=1000, nfold=5, stratified=False, shuffle=True,\n",
    "    early_stopping_rounds=50, verbose_eval=1, show_stdv=True, seed=0)\n",
    "# print('best num_boost_round:', len(cv_results['auc-mean']))\n",
    "# print('best cv score:', cv_results['auc-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e37bbb9fca44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lgb.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    }
   ],
   "source": [
    "# with open('lgb.txt', 'w') as f:\n",
    "#     f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_merged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d20096c96fdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"creative_id\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ad_id\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"product_id\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"product_category\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"advertiser_id\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"industry\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"click_times\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_merged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gender\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"user_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# split train data into 2 parts (cross validation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#random state is a seed value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_merged' is not defined"
     ]
    }
   ],
   "source": [
    "# !pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "features=[\"creative_id\",\"ad_id\",\"product_id\",\"product_category\",\"advertiser_id\",\"industry\",\"time\",\"click_times\"]\n",
    "\n",
    "df=train_merged.drop(columns=[\"gender\",\"user_id\"])\n",
    "# split train data into 2 parts (cross validation)\n",
    "train=df.sample(frac=0.8) #random state is a seed value\n",
    "test=df.drop(train.index)\n",
    "y_train=train.pop(\"age\")\n",
    "X_train=train\n",
    "y_test=test.pop(\"age\")\n",
    "X_test=test\n",
    "# display(X_train,y_train)\n",
    "# display(X_test,y_test)\n",
    "train_data.save_binary('age.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import lightgbm as lgb\n",
    "train_data = lgb.Dataset('age.bin')\n",
    "params = {'num_leaves': 2**7-1,\n",
    "          'min_data_in_leaf': 25, \n",
    "          'objective':'regression_l2',\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.1,\n",
    "          'min_child_samples': 20,\n",
    "          'boosting': 'gbdt',\n",
    "          'feature_fraction': 0.6,\n",
    "          'bagging_fraction': 0.9,\n",
    "          'bagging_seed': 11,\n",
    "          'metric': 'mae',\n",
    "          'seed':1024,\n",
    "          'lambda_l1': 0.2,\n",
    "          'nthread':12,\n",
    "         }\n",
    "print(\"start training\")\n",
    "cv_results = lgb.cv(\n",
    "    params, train_data, num_boost_round=1000, nfold=5, stratified=False, shuffle=True,\n",
    "    early_stopping_rounds=50, verbose_eval=10, show_stdv=True, seed=0)\n",
    "print('best num_boost_round:', len(cv_results['mae-mean']))\n",
    "print('best cv score:', cv_results['mae-mean'])\n",
    "# bst = lgb.train(param, train_data, num_round,categorical_feature=features)\n",
    "# bst.save_model('test_model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train, y_train, free_raw_data=False)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train,free_raw_data=False)\n",
    "params = {\n",
    "          'boosting_type': 'gbdt',\n",
    "          'objective': 'binary',\n",
    "          'metric': 'auc',\n",
    "          'nthread':12,\n",
    "          'learning_rate':0.1\n",
    "          }\n",
    " \n",
    "### 交叉验证(调参)\n",
    "print('交叉验证')\n",
    "max_auc = float('0')\n",
    "best_params = {}\n",
    " \n",
    "# 准确率\n",
    "print(\"调参1：提高准确率\")\n",
    "for num_leaves in range(5,100,5):\n",
    "    for max_depth in range(3,8,1):\n",
    "        params['num_leaves'] = num_leaves\n",
    "        params['max_depth'] = max_depth\n",
    " \n",
    "        cv_results = lgb.cv(\n",
    "                            params,\n",
    "                            lgb_train,\n",
    "                            seed=1,\n",
    "                            nfold=5,\n",
    "                            metrics=['auc'],\n",
    "                            early_stopping_rounds=10,\n",
    "                            verbose_eval=True\n",
    "                            )\n",
    "            \n",
    "        mean_auc = pd.Series(cv_results['auc-mean']).max()\n",
    "        boost_rounds = pd.Series(cv_results['auc-mean']).idxmax()\n",
    "            \n",
    "        if mean_auc >= max_auc:\n",
    "            max_auc = mean_auc\n",
    "            best_params['num_leaves'] = num_leaves\n",
    "            best_params['max_depth'] = max_depth\n",
    "if 'num_leaves' and 'max_depth' in best_params.keys():          \n",
    "    params['num_leaves'] = best_params['num_leaves']\n",
    "    params['max_depth'] = best_params['max_depth']\n",
    " \n",
    "# 过拟合\n",
    "print(\"调参2：降低过拟合\")\n",
    "for max_bin in range(5,256,10):\n",
    "    for min_data_in_leaf in range(1,102,10):\n",
    "            params['max_bin'] = max_bin\n",
    "            params['min_data_in_leaf'] = min_data_in_leaf\n",
    "            \n",
    "            cv_results = lgb.cv(\n",
    "                                params,\n",
    "                                lgb_train,\n",
    "                                seed=1,\n",
    "                                nfold=5,\n",
    "                                metrics=['auc'],\n",
    "                                early_stopping_rounds=10,\n",
    "                                verbose_eval=True\n",
    "                                )\n",
    "                    \n",
    "            mean_auc = pd.Series(cv_results['auc-mean']).max()\n",
    "            boost_rounds = pd.Series(cv_results['auc-mean']).idxmax()\n",
    " \n",
    "            if mean_auc >= max_auc:\n",
    "                max_auc = mean_auc\n",
    "                best_params['max_bin']= max_bin\n",
    "                best_params['min_data_in_leaf'] = min_data_in_leaf\n",
    "if 'max_bin' and 'min_data_in_leaf' in best_params.keys():\n",
    "    params['min_data_in_leaf'] = best_params['min_data_in_leaf']\n",
    "    params['max_bin'] = best_params['max_bin']\n",
    " \n",
    "print(\"调参3：降低过拟合\")\n",
    "for feature_fraction in [0.6,0.7,0.8,0.9,1.0]:\n",
    "    for bagging_fraction in [0.6,0.7,0.8,0.9,1.0]:\n",
    "        for bagging_freq in range(0,50,5):\n",
    "            params['feature_fraction'] = feature_fraction\n",
    "            params['bagging_fraction'] = bagging_fraction\n",
    "            params['bagging_freq'] = bagging_freq\n",
    "            \n",
    "            cv_results = lgb.cv(\n",
    "                                params,\n",
    "                                lgb_train,\n",
    "                                seed=1,\n",
    "                                nfold=5,\n",
    "                                metrics=['auc'],\n",
    "                                early_stopping_rounds=10,\n",
    "                                verbose_eval=True\n",
    "                                )\n",
    "                    \n",
    "            mean_auc = pd.Series(cv_results['auc-mean']).max()\n",
    "            boost_rounds = pd.Series(cv_results['auc-mean']).idxmax()\n",
    " \n",
    "            if mean_auc >= max_auc:\n",
    "                max_auc=mean_auc\n",
    "                best_params['feature_fraction'] = feature_fraction\n",
    "                best_params['bagging_fraction'] = bagging_fraction\n",
    "                best_params['bagging_freq'] = bagging_freq\n",
    " \n",
    "if 'feature_fraction' and 'bagging_fraction' and 'bagging_freq' in best_params.keys():\n",
    "    params['feature_fraction'] = best_params['feature_fraction']\n",
    "    params['bagging_fraction'] = best_params['bagging_fraction']\n",
    "    params['bagging_freq'] = best_params['bagging_freq']\n",
    " \n",
    " \n",
    "print(\"调参4：降低过拟合\")\n",
    "for lambda_l1 in [1e-5,1e-3,1e-1,0.0,0.1,0.3,0.5,0.7,0.9,1.0]:\n",
    "    for lambda_l2 in [1e-5,1e-3,1e-1,0.0,0.1,0.4,0.6,0.7,0.9,1.0]:\n",
    "        params['lambda_l1'] = lambda_l1\n",
    "        params['lambda_l2'] = lambda_l2\n",
    "        cv_results = lgb.cv(\n",
    "                            params,\n",
    "                            lgb_train,\n",
    "                            seed=1,\n",
    "                            nfold=5,\n",
    "                            metrics=['auc'],\n",
    "                            early_stopping_rounds=10,\n",
    "                            verbose_eval=True\n",
    "                            )\n",
    "                \n",
    "        mean_auc = pd.Series(cv_results['auc-mean']).max()\n",
    "        boost_rounds = pd.Series(cv_results['auc-mean']).idxmax()\n",
    " \n",
    "        if mean_auc >= max_auc:\n",
    "            max_auc=mean_auc\n",
    "            best_params['lambda_l1'] = lambda_l1\n",
    "            best_params['lambda_l2'] = lambda_l2\n",
    "if 'lambda_l1' and 'lambda_l2' in best_params.keys():\n",
    "    params['lambda_l1'] = best_params['lambda_l1']\n",
    "    params['lambda_l2'] = best_params['lambda_l2']\n",
    " \n",
    "print(\"调参5：降低过拟合2\")\n",
    "for min_split_gain in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "    params['min_split_gain'] = min_split_gain\n",
    "    \n",
    "    cv_results = lgb.cv(\n",
    "                        params,\n",
    "                        lgb_train,\n",
    "                        seed=1,\n",
    "                        nfold=5,\n",
    "                        metrics=['auc'],\n",
    "                        early_stopping_rounds=10,\n",
    "                        verbose_eval=True\n",
    "                        )\n",
    "            \n",
    "    mean_auc = pd.Series(cv_results['auc-mean']).max()\n",
    "    boost_rounds = pd.Series(cv_results['auc-mean']).idxmax()\n",
    " \n",
    "    if mean_auc >= max_auc:\n",
    "        max_auc=mean_auc\n",
    "        \n",
    "        best_params['min_split_gain'] = min_split_gain\n",
    "if 'min_split_gain' in best_params.keys():\n",
    "    params['min_split_gain'] = best_params['min_split_gain']\n",
    " \n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "df=tmpdf\n",
    "features=[\"creative_id\"]\n",
    "v = TfidfVectorizer(max_df=1.0,min_df=1,lowercase=False,tokenizer=lambda x:x)\n",
    "for feature in features:\n",
    "    cur=df.groupby(\"user_id\")[feature].apply(list)\n",
    "    v_fit = v.fit_transform(cur)\n",
    "    word=v.get_feature_names()\n",
    "    display(v_fit)\n",
    "    display(type(v_fit))\n",
    "#     for i in range(len(weight)):\n",
    "#         print(\"-----output feature={}, user_id={} tf-idf-----\".format(feature,i+1))\n",
    "#         for j in range(len(word)):\n",
    "#             print(word[j],weight[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_py3",
   "language": "python",
   "name": "conda_tensorflow2_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
