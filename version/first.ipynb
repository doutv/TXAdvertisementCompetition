{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "1         [71691, 90171, 122032, 209778, 821396, 877468,...\n",
       "2         [13069, 15558, 22013, 39714, 63441, 96192, 155...\n",
       "3         [66009, 72533, 392052, 593522, 599128, 661347,...\n",
       "4         [31070, 39588, 72989, 215041, 574787, 589886, ...\n",
       "5         [24333, 43235, 75011, 296145, 350759, 795508, ...\n",
       "                                ...                        \n",
       "899996    [92193, 114074, 654526, 931537, 939409, 145880...\n",
       "899997    [7400, 24333, 30210, 60330, 69204, 103918, 103...\n",
       "899998    [71752, 648402, 1251649, 1370659, 1779124, 230...\n",
       "899999    [12838, 12838, 12838, 12838, 122834, 279342, 3...\n",
       "900000    [234063, 285502, 423617, 1224107, 1405713, 180...\n",
       "Name: creative_id, Length: 900000, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<900000x2414321 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9965541 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tf-idf preprocess\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from scipy import sparse\n",
    "train_merged=pd.read_csv('train_merged.csv')\n",
    "df=train_merged\n",
    "v = TfidfVectorizer(max_df=50,lowercase=False,tokenizer=lambda x:x)\n",
    "cur=df.groupby(\"user_id\")[\"creative_id\"].apply(list)\n",
    "# cur.astype(int)\n",
    "display(cur)\n",
    "v_fit = v.fit_transform(cur)\n",
    "display(v_fit)\n",
    "sparse.save_npz('v_fit.npz', v_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899995</th>\n",
       "      <td>899996</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899996</th>\n",
       "      <td>899997</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899997</th>\n",
       "      <td>899998</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899998</th>\n",
       "      <td>899999</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899999</th>\n",
       "      <td>900000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  age  gender\n",
       "0             1    4       0\n",
       "1             2   10       0\n",
       "2             3    7       1\n",
       "3             4    5       0\n",
       "4             5    4       0\n",
       "...         ...  ...     ...\n",
       "899995   899996    5       0\n",
       "899996   899997    3       1\n",
       "899997   899998    4       1\n",
       "899998   899999    3       0\n",
       "899999   900000    3       1\n",
       "\n",
       "[900000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click_times_mean</th>\n",
       "      <th>advertiser_id_nunique</th>\n",
       "      <th>advertiser_id_count</th>\n",
       "      <th>industry_nunique</th>\n",
       "      <th>industry_count</th>\n",
       "      <th>time_nunique</th>\n",
       "      <th>time_count</th>\n",
       "      <th>product_category_nunique</th>\n",
       "      <th>product_category_count</th>\n",
       "      <th>product_id_nunique</th>\n",
       "      <th>product_id_count</th>\n",
       "      <th>ad_id_nunique</th>\n",
       "      <th>ad_id_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.076923</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.022222</td>\n",
       "      <td>36</td>\n",
       "      <td>45</td>\n",
       "      <td>15</td>\n",
       "      <td>45</td>\n",
       "      <td>28</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>20</td>\n",
       "      <td>45</td>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.030303</td>\n",
       "      <td>30</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899995</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899996</th>\n",
       "      <td>1.111111</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899997</th>\n",
       "      <td>1.071429</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899998</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899999</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        click_times_mean  advertiser_id_nunique  advertiser_id_count  \\\n",
       "0               1.076923                     12                   13   \n",
       "1               1.022222                     36                   45   \n",
       "2               1.000000                     28                   30   \n",
       "3               1.000000                     26                   29   \n",
       "4               1.030303                     30                   33   \n",
       "...                  ...                    ...                  ...   \n",
       "899995          1.000000                     12                   14   \n",
       "899996          1.111111                     13                   18   \n",
       "899997          1.071429                      9                   14   \n",
       "899998          1.000000                     16                   22   \n",
       "899999          1.000000                     10                   12   \n",
       "\n",
       "        industry_nunique  industry_count  time_nunique  time_count  \\\n",
       "0                      9              13            10          13   \n",
       "1                     15              45            28          45   \n",
       "2                      8              30            23          30   \n",
       "3                     10              29            15          29   \n",
       "4                     18              33            26          33   \n",
       "...                  ...             ...           ...         ...   \n",
       "899995                 5              14            12          14   \n",
       "899996                10              18            14          18   \n",
       "899997                 5              14            10          14   \n",
       "899998                14              22            17          22   \n",
       "899999                10              12            12          12   \n",
       "\n",
       "        product_category_nunique  product_category_count  product_id_nunique  \\\n",
       "0                              3                      13                   6   \n",
       "1                              3                      45                  20   \n",
       "2                              6                      30                  17   \n",
       "3                              6                      29                  18   \n",
       "4                              4                      33                   7   \n",
       "...                          ...                     ...                 ...   \n",
       "899995                         3                      14                   5   \n",
       "899996                         4                      18                  10   \n",
       "899997                         4                      14                   5   \n",
       "899998                         7                      22                   5   \n",
       "899999                         2                      12                   2   \n",
       "\n",
       "        product_id_count  ad_id_nunique  ad_id_count  \n",
       "0                     13             12           13  \n",
       "1                     45             42           45  \n",
       "2                     30             30           30  \n",
       "3                     29             29           29  \n",
       "4                     33             33           33  \n",
       "...                  ...            ...          ...  \n",
       "899995                14             13           14  \n",
       "899996                18             17           18  \n",
       "899997                14             14           14  \n",
       "899998                22             18           22  \n",
       "899999                12             12           12  \n",
       "\n",
       "[900000 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cross validation for gender\n",
    "%reset -f\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "user_info=pd.read_csv('user_info.csv')\n",
    "user_info.astype(int)\n",
    "display(user_info)\n",
    "agg=pd.read_csv('agg.csv')\n",
    "# agg.astype(int)\n",
    "display(agg)\n",
    "v_fit=sparse.load_npz('v_fit.npz')\n",
    "num_train=int(user_info.shape[0]*0.8)\n",
    "y_train=user_info[\"gender\"].iloc[:num_train]\n",
    "y_test=user_info[\"gender\"].iloc[num_train:]\n",
    "\n",
    "# X_train=sparse.csr_matrix(v_fit[:num_train,:],dtype=float).tocsr()\n",
    "# X_test=sparse.csr_matrix(v_fit[num_train:,:],dtype=float).tocsr()\n",
    "\n",
    "X_train=sparse.csr_matrix(agg.iloc[:num_train])\n",
    "X_test=sparse.csr_matrix(agg.iloc[num_train:])\n",
    "X_train=sparse.hstack((v_fit[:num_train,:],X_train),dtype=float).tocsr()\n",
    "X_test=sparse.hstack((v_fit[num_train:,:],X_test),dtype=float).tocsr()\n",
    "\n",
    "import lightgbm as lgb\n",
    "train_data = lgb.Dataset(X_train,y_train)\n",
    "train_data.save_binary('CountVectorizer_train_gender.bin')\n",
    "# test_data=lgb.Dataset(X_test,y_test)\n",
    "# test_data.save_binary('CountVectorizer_test_gender.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "[10]\tcv_agg's auc: 0.6231 + 0.00142673\n",
      "[20]\tcv_agg's auc: 0.628205 + 0.00127108\n",
      "[30]\tcv_agg's auc: 0.641034 + 0.000831938\n",
      "[40]\tcv_agg's auc: 0.648032 + 0.000781777\n",
      "[50]\tcv_agg's auc: 0.656094 + 0.00104904\n",
      "[60]\tcv_agg's auc: 0.66377 + 0.00129256\n",
      "[70]\tcv_agg's auc: 0.668926 + 0.00125677\n",
      "[80]\tcv_agg's auc: 0.673008 + 0.00128241\n",
      "[90]\tcv_agg's auc: 0.676582 + 0.00132133\n",
      "[100]\tcv_agg's auc: 0.679915 + 0.00122345\n",
      "[110]\tcv_agg's auc: 0.683032 + 0.00119218\n",
      "[120]\tcv_agg's auc: 0.685907 + 0.00122485\n",
      "[130]\tcv_agg's auc: 0.688598 + 0.00119378\n",
      "[140]\tcv_agg's auc: 0.691029 + 0.00108103\n",
      "[150]\tcv_agg's auc: 0.693345 + 0.00114\n",
      "[160]\tcv_agg's auc: 0.695466 + 0.00114003\n",
      "[170]\tcv_agg's auc: 0.697398 + 0.0011217\n",
      "[180]\tcv_agg's auc: 0.699246 + 0.00114483\n",
      "[190]\tcv_agg's auc: 0.700961 + 0.00117523\n"
     ]
    }
   ],
   "source": [
    "# cross validation for gender\n",
    "%reset -f\n",
    "import lightgbm as lgb\n",
    "train_data = lgb.Dataset('CountVectorizer_train_gender.bin')\n",
    "lgb_params = {'num_leaves': 2**7-1,\n",
    "              'min_data_in_leaf': 25, \n",
    "              'objective':'binary',\n",
    "              'max_depth': -1,\n",
    "              'learning_rate': 0.1,\n",
    "              'boosting': 'gbdt',\n",
    "              'feature_fraction': 0.6,\n",
    "              'bagging_fraction': 0.9,\n",
    "              'bagging_seed': 11,\n",
    "              'metric': 'auc',\n",
    "              'seed':1024,\n",
    "              'nthread':12,\n",
    "             }\n",
    "print(\"start training\")\n",
    "cv_results = lgb.cv(\n",
    "    lgb_params, train_data, num_boost_round=1000, nfold=5, shuffle=True,\n",
    "    early_stopping_rounds=50, verbose_eval=10, show_stdv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Cannot add validation data, since it has different bin mappers with training data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1da593e256e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"start training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m model = lgb.train(\n\u001b[0;32m---> 24\u001b[0;31m     lgb_params, train_data,valid_sets=[test_data],num_boost_round=1000,verbose_eval=10)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_valid_set\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduced_valid_sets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_valid_sets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_valid_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reverse_update_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36madd_valid\u001b[0;34m(self, data, name)\u001b[0m\n\u001b[1;32m   1893\u001b[0m         _safe_call(_LIB.LGBM_BoosterAddValidData(\n\u001b[1;32m   1894\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1895\u001b[0;31m             data.construct().handle))\n\u001b[0m\u001b[1;32m   1896\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1897\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_valid_sets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \"\"\"\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLightGBMError\u001b[0m: Cannot add validation data, since it has different bin mappers with training data"
     ]
    }
   ],
   "source": [
    "# predict gender\n",
    "%reset -f\n",
    "import lightgbm as lgb\n",
    "train_data = lgb.Dataset('CountVectorizer_train_gender.bin')\n",
    "# test_data = lgb.Dataset('CountVectorizer_test_gender.bin')\n",
    "\n",
    "lgb_params = {'num_leaves': 2**7-1,\n",
    "              'min_data_in_leaf': 25, \n",
    "              'objective':'binary',\n",
    "              'max_depth': -1,\n",
    "              'learning_rate': 0.1,\n",
    "              'boosting': 'gbdt',\n",
    "              'feature_fraction': 0.6,\n",
    "              'bagging_fraction': 0.9,\n",
    "              'bagging_seed': 11,\n",
    "              'metric': 'auc',\n",
    "              'seed':1024,\n",
    "              'nthread':12,\n",
    "             }\n",
    "print(\"start training\")\n",
    "model = lgb.LGBMClassifier(lgb_params, train_data,num_boost_round=200)\n",
    "model=lgb.LGBMClassifier(boosting_type='gbdt',\n",
    "                         objective='binary',\n",
    "                         metrics='auc',\n",
    "                         learning_rate=0.1,\n",
    "                         n_estimators=200, \n",
    "                         max_depth=-1, \n",
    "                         num_leaves= 2**7-1,\n",
    "                         feature_fraction= 0.6,\n",
    "                         bagging_fraction=0.9,\n",
    "                         nthread=12)\n",
    "print(\"training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict gender\n",
    "%reset -f\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "user_info=pd.read_csv('user_info.csv')\n",
    "user_info.astype(int)\n",
    "# display(user_info)\n",
    "agg=pd.read_csv('agg.csv')\n",
    "# display(agg)\n",
    "v_fit=sparse.load_npz('v_fit.npz')\n",
    "num_train=int(user_info.shape[0]*0.8)\n",
    "y_test=user_info[\"gender\"].iloc[num_train:]\n",
    "# display(y_test)\n",
    "X_test=sparse.csr_matrix(agg.iloc[num_train:])\n",
    "X_test=sparse.hstack((v_fit[num_train:,:],X_test),dtype=float).tocsr()\n",
    "print(\"start predicting\")\n",
    "model=lgb.Booster(model_file='model.txt')\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred=(y_pred>0.5)*1\n",
    "print(\"acc:\",metrics.accuracy_score(y_test,y_pred))\n",
    "print(\"acc:\",metrics.roc_auc_score(y_test,y_pred))\n",
    "# submission=pd.DataFrame(result,columns=[\"gender\"])\n",
    "# submission[\"user_id\"]=[i for i in range(num_train+1,user_info.shape[0]+1)]\n",
    "# display(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "[10]\tcv_agg's multi_error: 0.773665 + 0.00104111\n",
      "[20]\tcv_agg's multi_error: 0.7718 + 0.00112992\n",
      "[30]\tcv_agg's multi_error: 0.769813 + 0.00108029\n",
      "[40]\tcv_agg's multi_error: 0.767744 + 0.00119807\n",
      "[50]\tcv_agg's multi_error: 0.766378 + 0.00120966\n",
      "[60]\tcv_agg's multi_error: 0.764989 + 0.00114233\n",
      "[70]\tcv_agg's multi_error: 0.763919 + 0.00123168\n",
      "[80]\tcv_agg's multi_error: 0.763035 + 0.00112768\n"
     ]
    }
   ],
   "source": [
    "# cross validation for age\n",
    "%reset -f\n",
    "# !pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "user_info=pd.read_csv('user_info.csv')\n",
    "agg=pd.read_csv('agg.csv')\n",
    "v_fit=sparse.load_npz('v_fit.npz')\n",
    "num_train=int(user_info.shape[0]*0.8)\n",
    "y_train=user_info[\"age\"].iloc[:num_train]\n",
    "y_test=user_info[\"age\"].iloc[num_train:]\n",
    "X_train=sparse.csr_matrix(agg.iloc[:num_train])\n",
    "X_test=sparse.csr_matrix(agg.iloc[num_train:])\n",
    "X_train=sparse.hstack((v_fit[:num_train,:],X_train),dtype=float).tocsr()\n",
    "X_test=sparse.hstack((v_fit[num_train:,:],X_test),dtype=float).tocsr()\n",
    "train_data = lgb.Dataset(X_train,y_train)\n",
    "train_data.save_binary('CountVectorizer_train_age.bin')\n",
    "\n",
    "lgb_params = {'num_leaves': 2**6-1,\n",
    "              'min_data_in_leaf': 25, \n",
    "              'objective':'multiclass',\n",
    "              'num_class':11,\n",
    "              'max_depth': -1,\n",
    "              'learning_rate': 0.1,\n",
    "              'boosting': 'gbdt',\n",
    "              'feature_fraction': 0.6,\n",
    "              'bagging_fraction': 0.9,\n",
    "              'bagging_seed': 11,\n",
    "              'metric': 'multi_error',\n",
    "              'seed':1024,\n",
    "              'nthread':12,\n",
    "              'lambda_l1': 0.2,\n",
    "             }\n",
    "print(\"start training\")\n",
    "cv_results = lgb.cv(\n",
    "    lgb_params, train_data, num_boost_round=1000, nfold=5, stratified=False, shuffle=True,\n",
    "    early_stopping_rounds=50, verbose_eval=10, show_stdv=True, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7126119cd7d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m              }\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"start training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgb_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"age_model.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training completed!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1974\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1975\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1977\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# predict age\n",
    "%reset -f\n",
    "import lightgbm as lgb\n",
    "train_data = lgb.Dataset('CountVectorizer_train_age.bin')\n",
    "lgb_params = {'num_leaves': 2**6-1,\n",
    "              'min_data_in_leaf': 25, \n",
    "              'objective':'multiclass',\n",
    "              'num_class':11,\n",
    "              'max_depth': -1,\n",
    "              'learning_rate': 0.1,\n",
    "              'boosting': 'gbdt',\n",
    "              'feature_fraction': 0.6,\n",
    "              'bagging_fraction': 0.9,\n",
    "              'bagging_seed': 11,\n",
    "              'metric': 'multi_error',\n",
    "              'seed':1024,\n",
    "              'nthread':12,\n",
    "              'lambda_l1': 0.2,\n",
    "             }\n",
    "print(\"start training\")\n",
    "model = lgb.train(lgb_params, train_data,num_boost_round=200)\n",
    "model.save_model(\"age_model.txt\")\n",
    "print(\"training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720000    3\n",
       "720001    2\n",
       "720002    2\n",
       "720003    3\n",
       "720004    5\n",
       "         ..\n",
       "899995    5\n",
       "899996    3\n",
       "899997    4\n",
       "899998    3\n",
       "899999    3\n",
       "Name: age, Length: 180000, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start predicting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.74877228, 4.60749918, 4.16929228, ..., 4.28402148, 4.44051075,\n",
       "       4.15519538])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ffde72f36710>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"acc:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"acc:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "# predict age\n",
    "%reset -f\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "user_info=pd.read_csv('user_info.csv')\n",
    "user_info.astype(int)\n",
    "agg=pd.read_csv('agg.csv')\n",
    "v_fit=sparse.load_npz('v_fit.npz')\n",
    "num_train=int(user_info.shape[0]*0.8)\n",
    "y_test=user_info[\"age\"].iloc[num_train:]\n",
    "display(y_test)\n",
    "X_test=sparse.csr_matrix(agg.iloc[num_train:])\n",
    "X_test=sparse.hstack((v_fit[num_train:,:],X_test),dtype=float).tocsr()\n",
    "print(\"start predicting\")\n",
    "model=lgb.Booster(model_file='age_model.txt')\n",
    "y_pred=model.predict(X_test)\n",
    "display(y_pred)\n",
    "print(\"acc:\",metrics.accuracy_score(y_test,y_pred))\n",
    "print(\"acc:\",metrics.roc_auc_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "count  180000.0\n",
       "mean        1.0\n",
       "std         0.0\n",
       "min         1.0\n",
       "25%         1.0\n",
       "50%         1.0\n",
       "75%         1.0\n",
       "max         1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "df=tmpdf\n",
    "features=[\"creative_id\"]\n",
    "v = TfidfVectorizer(max_df=1.0,min_df=1,lowercase=False,tokenizer=lambda x:x)\n",
    "for feature in features:\n",
    "    cur=df.groupby(\"user_id\")[feature].apply(list)\n",
    "    v_fit = v.fit_transform(cur)\n",
    "    word=v.get_feature_names()\n",
    "    display(v_fit)\n",
    "    display(type(v_fit))\n",
    "#     for i in range(len(weight)):\n",
    "#         print(\"-----output feature={}, user_id={} tf-idf-----\".format(feature,i+1))\n",
    "#         for j in range(len(word)):\n",
    "#             print(word[j],weight[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_py3",
   "language": "python",
   "name": "conda_tensorflow2_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
