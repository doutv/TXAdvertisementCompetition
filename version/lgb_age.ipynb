{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<900000x2533225 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 48745802 stored elements in COOrdinate format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tf-idf preprocess\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from scipy import sparse\n",
    "train_merged=pd.read_csv('train_merged.csv')\n",
    "df=train_merged\n",
    "v = TfidfVectorizer(lowercase=False,tokenizer=lambda x:x)\n",
    "creative_id=df.groupby(\"user_id\")[\"creative_id\"].apply(list)\n",
    "creative_id = v.fit_transform(creative_id)\n",
    "advertiser_id=df.groupby(\"user_id\")[\"advertiser_id\"].apply(list)\n",
    "advertiser_id = v.fit_transform(advertiser_id)\n",
    "cr_ad=sparse.hstack((creative_id,advertiser_id),dtype=float)\n",
    "display(cr_ad)\n",
    "sparse.save_npz('cr_ad.npz', cr_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<900000x2533225 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 48745802 stored elements in COOrdinate format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cross validation for age\n",
    "%reset -f\n",
    "# !pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "user_info=pd.read_csv('user_info.csv')\n",
    "X_train=sparse.load_npz('cr_ad.npz')\n",
    "y_train=user_info[\"age\"]\n",
    "\n",
    "train_data = lgb.Dataset(X_train,y_train)\n",
    "train_data.save_binary('CountVectorizer_train_age.bin')\n",
    "display(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start cv\n",
      "[10]\tcv_agg's multi_error: 0.773837 + 0.00108892\n",
      "[20]\tcv_agg's multi_error: 0.772143 + 0.00108821\n",
      "[30]\tcv_agg's multi_error: 0.770558 + 0.00103075\n",
      "[40]\tcv_agg's multi_error: 0.769079 + 0.00107046\n",
      "[50]\tcv_agg's multi_error: 0.768085 + 0.00111039\n",
      "[60]\tcv_agg's multi_error: 0.767147 + 0.00110585\n",
      "[70]\tcv_agg's multi_error: 0.766379 + 0.00116012\n",
      "[80]\tcv_agg's multi_error: 0.765656 + 0.00116009\n",
      "[90]\tcv_agg's multi_error: 0.765029 + 0.00118739\n",
      "[100]\tcv_agg's multi_error: 0.764253 + 0.00120462\n",
      "[110]\tcv_agg's multi_error: 0.763796 + 0.00117341\n",
      "[120]\tcv_agg's multi_error: 0.763329 + 0.00120664\n",
      "[130]\tcv_agg's multi_error: 0.76284 + 0.0011866\n",
      "[140]\tcv_agg's multi_error: 0.762506 + 0.00115682\n",
      "[150]\tcv_agg's multi_error: 0.762025 + 0.00111838\n",
      "[160]\tcv_agg's multi_error: 0.761746 + 0.00107285\n",
      "[170]\tcv_agg's multi_error: 0.761478 + 0.000996448\n",
      "[180]\tcv_agg's multi_error: 0.761132 + 0.00103269\n",
      "[190]\tcv_agg's multi_error: 0.760799 + 0.000942717\n",
      "[200]\tcv_agg's multi_error: 0.760576 + 0.000930784\n",
      "[210]\tcv_agg's multi_error: 0.76024 + 0.0010012\n",
      "[220]\tcv_agg's multi_error: 0.76005 + 0.000983745\n",
      "[230]\tcv_agg's multi_error: 0.759897 + 0.00102586\n",
      "[240]\tcv_agg's multi_error: 0.759728 + 0.000906567\n",
      "[250]\tcv_agg's multi_error: 0.759594 + 0.000965349\n",
      "[260]\tcv_agg's multi_error: 0.759431 + 0.00100665\n",
      "[270]\tcv_agg's multi_error: 0.759253 + 0.000999379\n",
      "[280]\tcv_agg's multi_error: 0.759036 + 0.00101404\n",
      "[290]\tcv_agg's multi_error: 0.758921 + 0.000939166\n",
      "[300]\tcv_agg's multi_error: 0.758868 + 0.00101623\n",
      "[310]\tcv_agg's multi_error: 0.758743 + 0.00104266\n",
      "[320]\tcv_agg's multi_error: 0.758628 + 0.000998674\n",
      "[330]\tcv_agg's multi_error: 0.758501 + 0.000971393\n",
      "[340]\tcv_agg's multi_error: 0.758433 + 0.000922703\n",
      "[350]\tcv_agg's multi_error: 0.758311 + 0.000885534\n",
      "[360]\tcv_agg's multi_error: 0.758235 + 0.000890509\n",
      "[370]\tcv_agg's multi_error: 0.758157 + 0.000952454\n",
      "[380]\tcv_agg's multi_error: 0.75806 + 0.000923153\n",
      "[390]\tcv_agg's multi_error: 0.757906 + 0.000984443\n",
      "[400]\tcv_agg's multi_error: 0.75781 + 0.00097321\n",
      "[410]\tcv_agg's multi_error: 0.757786 + 0.00100955\n",
      "[420]\tcv_agg's multi_error: 0.757758 + 0.00100718\n",
      "[430]\tcv_agg's multi_error: 0.757575 + 0.000981183\n",
      "[440]\tcv_agg's multi_error: 0.757525 + 0.000998983\n",
      "[450]\tcv_agg's multi_error: 0.757463 + 0.000984541\n",
      "[460]\tcv_agg's multi_error: 0.757358 + 0.000946481\n",
      "[470]\tcv_agg's multi_error: 0.757313 + 0.000987353\n",
      "[480]\tcv_agg's multi_error: 0.757219 + 0.000950081\n",
      "[490]\tcv_agg's multi_error: 0.757157 + 0.000979591\n",
      "[500]\tcv_agg's multi_error: 0.757051 + 0.000989398\n",
      "[510]\tcv_agg's multi_error: 0.757035 + 0.00100007\n",
      "[520]\tcv_agg's multi_error: 0.757 + 0.000991281\n",
      "[530]\tcv_agg's multi_error: 0.756976 + 0.000995501\n",
      "[540]\tcv_agg's multi_error: 0.756915 + 0.00097955\n",
      "[550]\tcv_agg's multi_error: 0.756892 + 0.000976682\n",
      "[560]\tcv_agg's multi_error: 0.75681 + 0.00100846\n",
      "[570]\tcv_agg's multi_error: 0.756825 + 0.00099077\n",
      "[580]\tcv_agg's multi_error: 0.756789 + 0.000969735\n",
      "[590]\tcv_agg's multi_error: 0.756726 + 0.000942007\n",
      "[600]\tcv_agg's multi_error: 0.756622 + 0.000963539\n",
      "[610]\tcv_agg's multi_error: 0.756607 + 0.000938365\n",
      "[620]\tcv_agg's multi_error: 0.756597 + 0.000928408\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4ba72239cdee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m cv_results = lgb.cv(\n\u001b[1;32m     21\u001b[0m     \u001b[0mlgb_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratified\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     verbose_eval=10, show_stdv=True, seed=0)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks, eval_train_metric)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                     \u001b[0mend_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m--> 564\u001b[0;31m         \u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_agg_cv_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_train_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mhandler_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboosters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m                 \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandler_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1974\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1975\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1977\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# cross validation for age\n",
    "%reset -f\n",
    "import lightgbm as lgb\n",
    "train_data = lgb.Dataset('CountVectorizer_train_age.bin')\n",
    "lgb_params = {'num_leaves': 2**6-1,\n",
    "              'min_data_in_leaf': 25, \n",
    "              'objective':'multiclass',\n",
    "              'num_class':10,\n",
    "              'max_depth': -1,\n",
    "              'learning_rate': 0.1,\n",
    "              'boosting': 'gbdt',\n",
    "              'feature_fraction': 0.6,\n",
    "              'bagging_fraction': 0.9,\n",
    "              'bagging_seed': 11,\n",
    "              'metric': 'multi_error',\n",
    "              'seed':1024,\n",
    "              'nthread':12,\n",
    "             }\n",
    "print(\"start cv\")\n",
    "cv_results = lgb.cv(\n",
    "    lgb_params, train_data, num_boost_round=1000, nfold=5, stratified=False, shuffle=True,\n",
    "    verbose_eval=10, show_stdv=True, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "training completed!\n"
     ]
    }
   ],
   "source": [
    "# predict age\n",
    "%reset -f\n",
    "import lightgbm as lgb\n",
    "train_data = lgb.Dataset('CountVectorizer_train_age.bin')\n",
    "lgb_params = {'num_leaves': 2**6-1,\n",
    "              'min_data_in_leaf': 25, \n",
    "              'objective':'multiclass',\n",
    "              'num_class':10,\n",
    "              'max_depth': -1,\n",
    "              'learning_rate': 0.1,\n",
    "              'boosting': 'gbdt',\n",
    "              'feature_fraction': 0.6,\n",
    "              'bagging_fraction': 0.9,\n",
    "              'bagging_seed': 11,\n",
    "              'metric': 'multi_error',\n",
    "              'seed':1024,\n",
    "              'nthread':12,\n",
    "              'lambda_l1': 0.2,\n",
    "             }\n",
    "print(\"start training\")\n",
    "model = lgb.train(lgb_params, train_data,num_boost_round=200)\n",
    "model.save_model(\"age_model.txt\")\n",
    "print(\"training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Requirement already satisfied: lightgbm in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from lightgbm) (1.18.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from lightgbm) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from lightgbm) (0.22.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from scikit-learn->lightgbm) (0.14.1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "720000    2\n",
       "720001    1\n",
       "720002    1\n",
       "720003    2\n",
       "720004    4\n",
       "         ..\n",
       "899995    4\n",
       "899996    2\n",
       "899997    3\n",
       "899998    2\n",
       "899999    2\n",
       "Name: age, Length: 180000, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start predicting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.07672395, 0.21548171, 0.22838336, ..., 0.02785875, 0.01380599,\n",
       "        0.00671158],\n",
       "       [0.00976268, 0.07982621, 0.20515466, ..., 0.04191782, 0.01981351,\n",
       "        0.00462914],\n",
       "       [0.03804853, 0.17869382, 0.23576319, ..., 0.04120684, 0.02223909,\n",
       "        0.01036169],\n",
       "       ...,\n",
       "       [0.02579289, 0.15219781, 0.23197627, ..., 0.03700645, 0.02087638,\n",
       "        0.01075989],\n",
       "       [0.01616925, 0.13558498, 0.23386216, ..., 0.04461791, 0.01773838,\n",
       "        0.00649407],\n",
       "       [0.01732835, 0.12255001, 0.24882467, ..., 0.02514533, 0.01428848,\n",
       "        0.00439648]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-dbc45d883d0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"acc:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"acc:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "# predict age\n",
    "%reset -f\n",
    "# ! pip install lightgbm\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "user_info=pd.read_csv('user_info.csv')\n",
    "agg=pd.read_csv('agg.csv')\n",
    "v_fit=sparse.load_npz('v_fit.npz')\n",
    "num_train=int(user_info.shape[0]*0.8)\n",
    "y_test=user_info[\"age\"].iloc[num_train:]\n",
    "display(y_test)\n",
    "X_test=sparse.csr_matrix(agg.iloc[num_train:])\n",
    "X_test=sparse.hstack((v_fit[num_train:,:],X_test),dtype=float).tocsr()\n",
    "print(\"start predicting\")\n",
    "model=lgb.Booster(model_file='age_model.txt')\n",
    "y_pred=model.predict(X_test)\n",
    "display(y_pred)\n",
    "y_pred.round(0)\n",
    "print(\"acc:\",metrics.accuracy_score(y_test,y_pred))\n",
    "print(\"acc:\",metrics.roc_auc_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "count  180000.0\n",
       "mean        1.0\n",
       "std         0.0\n",
       "min         1.0\n",
       "25%         1.0\n",
       "50%         1.0\n",
       "75%         1.0\n",
       "max         1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "df=tmpdf\n",
    "features=[\"creative_id\"]\n",
    "v = TfidfVectorizer(max_df=1.0,min_df=1,lowercase=False,tokenizer=lambda x:x)\n",
    "for feature in features:\n",
    "    cur=df.groupby(\"user_id\")[feature].apply(list)\n",
    "    v_fit = v.fit_transform(cur)\n",
    "    word=v.get_feature_names()\n",
    "    display(v_fit)\n",
    "    display(type(v_fit))\n",
    "#     for i in range(len(weight)):\n",
    "#         print(\"-----output feature={}, user_id={} tf-idf-----\".format(feature,i+1))\n",
    "#         for j in range(len(word)):\n",
    "#             print(word[j],weight[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_py3",
   "language": "python",
   "name": "conda_tensorflow2_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
