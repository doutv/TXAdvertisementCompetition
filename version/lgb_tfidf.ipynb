{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building third tfidf...\n",
      "saving train attrubutes...\n",
      "preprocessing predict data...\n",
      "reading...\n",
      "extracting...\n",
      "building first tfidf...\n",
      "building second tfidf...\n",
      "building third tfidf...\n",
      "saving train attrubutes...\n"
     ]
    }
   ],
   "source": [
    "# tf-idf preprocess\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import sparse\n",
    "\n",
    "print('reading...')\n",
    "df = pd.read_csv('./train_merged.csv')\n",
    "print('extracting...')\n",
    "creative_id = df.groupby('user_id')['creative_id'].apply(list)\n",
    "advertiser_id = df.groupby('user_id')['advertiser_id'].apply(list)\n",
    "ad_id = df.groupby('user_id')['ad_id'].apply(list)\n",
    "del df\n",
    "print('building first tfidf...')\n",
    "v_creat = TfidfVectorizer(lowercase=False,tokenizer=lambda x:x)\n",
    "X_creat = v_creat.fit_transform(creative_id)\n",
    "del creative_id\n",
    "print('building second tfidf...')\n",
    "v_adver = TfidfVectorizer(lowercase=False,tokenizer=lambda x:x)\n",
    "X_adver = v_adver.fit_transform(advertiser_id)\n",
    "del advertiser_id\n",
    "print('building third tfidf...')\n",
    "v_adid = TfidfVectorizer(lowercase=False,tokenizer=lambda x:x)\n",
    "X_adid = v_adid.fit_transform(ad_id)\n",
    "del ad_id\n",
    "print('saving train attrubutes...')\n",
    "train_attr = sparse.hstack((X_creat, X_adver, X_adid), dtype=float)\n",
    "del X_creat, X_adver, X_adid\n",
    "sparse.save_npz('./train_attr.npz', train_attr)\n",
    "del train_attr\n",
    "\n",
    "print('preprocessing predict data...')\n",
    "print('reading...')\n",
    "df = pd.read_csv('./predict_merged.csv')\n",
    "print('extracting...')\n",
    "creative_id = df.groupby('user_id')['creative_id'].apply(list)\n",
    "advertiser_id = df.groupby('user_id')['advertiser_id'].apply(list)\n",
    "ad_id = df.groupby('user_id')['ad_id'].apply(list)\n",
    "del df\n",
    "print('building first tfidf...')\n",
    "X_creat = v_creat.transform(creative_id)\n",
    "del creative_id\n",
    "print('building second tfidf...')\n",
    "X_adver = v_adver.transform(advertiser_id)\n",
    "del advertiser_id\n",
    "print('building third tfidf...')\n",
    "X_adid = v_adid.transform(ad_id)\n",
    "del ad_id\n",
    "print('saving predict attrubutes...')\n",
    "train_attr = sparse.hstack((X_creat, X_adver, X_adid), dtype=float)\n",
    "del X_creat, X_adver, X_adid\n",
    "sparse.save_npz('./predict_attr.npz', train_attr)\n",
    "del train_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "data is prepared.\n",
      "start training...\n",
      "fold n°1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([180000, 180001, 180002, ..., 899997, 899998, 899999])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([     0,      1,      2, ..., 179997, 179998, 179999])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<720000x4797415 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 61014420 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<180000x4797415 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 15292962 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's auc: 0.90759\tvalid_1's auc: 0.907775\n",
      "[20]\ttraining's auc: 0.923606\tvalid_1's auc: 0.923668\n",
      "[30]\ttraining's auc: 0.934325\tvalid_1's auc: 0.934182\n",
      "[40]\ttraining's auc: 0.941491\tvalid_1's auc: 0.940933\n",
      "[50]\ttraining's auc: 0.946735\tvalid_1's auc: 0.945849\n",
      "[60]\ttraining's auc: 0.950365\tvalid_1's auc: 0.949204\n",
      "[70]\ttraining's auc: 0.953095\tvalid_1's auc: 0.951616\n",
      "[80]\ttraining's auc: 0.9553\tvalid_1's auc: 0.953608\n",
      "[90]\ttraining's auc: 0.95708\tvalid_1's auc: 0.955199\n",
      "[100]\ttraining's auc: 0.9586\tvalid_1's auc: 0.956485\n",
      "[110]\ttraining's auc: 0.959854\tvalid_1's auc: 0.957572\n",
      "[120]\ttraining's auc: 0.960932\tvalid_1's auc: 0.958497\n",
      "[130]\ttraining's auc: 0.961924\tvalid_1's auc: 0.959288\n",
      "[140]\ttraining's auc: 0.962835\tvalid_1's auc: 0.959941\n",
      "[150]\ttraining's auc: 0.963644\tvalid_1's auc: 0.960571\n",
      "[160]\ttraining's auc: 0.96439\tvalid_1's auc: 0.961153\n",
      "[170]\ttraining's auc: 0.965088\tvalid_1's auc: 0.961661\n",
      "[180]\ttraining's auc: 0.965744\tvalid_1's auc: 0.962096\n",
      "[190]\ttraining's auc: 0.966328\tvalid_1's auc: 0.962518\n",
      "[200]\ttraining's auc: 0.966926\tvalid_1's auc: 0.96292\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.966926\tvalid_1's auc: 0.96292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00309808, 0.19907862, 0.06506072, ..., 0.00135544, 0.00032135,\n",
       "       0.00025179])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([     0,      1,      2, ..., 899997, 899998, 899999])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([180000, 180001, 180002, ..., 359997, 359998, 359999])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<720000x4797415 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 61050242 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<180000x4797415 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 15257140 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's auc: 0.905787\tvalid_1's auc: 0.904623\n",
      "[20]\ttraining's auc: 0.923206\tvalid_1's auc: 0.922039\n",
      "[30]\ttraining's auc: 0.933985\tvalid_1's auc: 0.932481\n",
      "[40]\ttraining's auc: 0.941623\tvalid_1's auc: 0.939989\n",
      "[50]\ttraining's auc: 0.946682\tvalid_1's auc: 0.944762\n",
      "[60]\ttraining's auc: 0.950385\tvalid_1's auc: 0.948329\n",
      "[70]\ttraining's auc: 0.953142\tvalid_1's auc: 0.950882\n",
      "[80]\ttraining's auc: 0.955346\tvalid_1's auc: 0.952875\n",
      "[90]\ttraining's auc: 0.957166\tvalid_1's auc: 0.954583\n",
      "[100]\ttraining's auc: 0.958612\tvalid_1's auc: 0.955871\n",
      "[110]\ttraining's auc: 0.959875\tvalid_1's auc: 0.95697\n",
      "[120]\ttraining's auc: 0.960992\tvalid_1's auc: 0.957923\n",
      "[130]\ttraining's auc: 0.96198\tvalid_1's auc: 0.958746\n",
      "[140]\ttraining's auc: 0.962857\tvalid_1's auc: 0.959455\n",
      "[150]\ttraining's auc: 0.963662\tvalid_1's auc: 0.960101\n",
      "[160]\ttraining's auc: 0.964399\tvalid_1's auc: 0.960631\n",
      "[170]\ttraining's auc: 0.965089\tvalid_1's auc: 0.961133\n",
      "[180]\ttraining's auc: 0.965758\tvalid_1's auc: 0.961554\n",
      "[190]\ttraining's auc: 0.966353\tvalid_1's auc: 0.961988\n",
      "[200]\ttraining's auc: 0.966927\tvalid_1's auc: 0.962339\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.966927\tvalid_1's auc: 0.962339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00522331, 0.39777132, 0.12928408, ..., 0.00232803, 0.00065041,\n",
       "       0.001434  ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([     0,      1,      2, ..., 899997, 899998, 899999])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([360000, 360001, 360002, ..., 539997, 539998, 539999])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<720000x4797415 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 61069614 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<180000x4797415 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 15237768 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's auc: 0.908018\tvalid_1's auc: 0.909099\n",
      "[20]\ttraining's auc: 0.92376\tvalid_1's auc: 0.924369\n",
      "[30]\ttraining's auc: 0.93384\tvalid_1's auc: 0.934121\n",
      "[40]\ttraining's auc: 0.941381\tvalid_1's auc: 0.941242\n",
      "[50]\ttraining's auc: 0.946446\tvalid_1's auc: 0.945994\n",
      "[60]\ttraining's auc: 0.950035\tvalid_1's auc: 0.949367\n",
      "[70]\ttraining's auc: 0.952781\tvalid_1's auc: 0.951809\n",
      "[80]\ttraining's auc: 0.955047\tvalid_1's auc: 0.953907\n",
      "[90]\ttraining's auc: 0.956848\tvalid_1's auc: 0.955514\n",
      "[100]\ttraining's auc: 0.958334\tvalid_1's auc: 0.956815\n",
      "[110]\ttraining's auc: 0.959617\tvalid_1's auc: 0.957912\n",
      "[120]\ttraining's auc: 0.960718\tvalid_1's auc: 0.958788\n",
      "[130]\ttraining's auc: 0.961709\tvalid_1's auc: 0.959601\n",
      "[140]\ttraining's auc: 0.962586\tvalid_1's auc: 0.960271\n",
      "[150]\ttraining's auc: 0.963402\tvalid_1's auc: 0.96091\n",
      "[160]\ttraining's auc: 0.964148\tvalid_1's auc: 0.961448\n",
      "[170]\ttraining's auc: 0.964884\tvalid_1's auc: 0.961951\n",
      "[180]\ttraining's auc: 0.965521\tvalid_1's auc: 0.962373\n",
      "[190]\ttraining's auc: 0.966154\tvalid_1's auc: 0.962814\n",
      "[200]\ttraining's auc: 0.966745\tvalid_1's auc: 0.963192\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.966745\tvalid_1's auc: 0.963192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.0068756 , 0.59707468, 0.20042515, ..., 0.00388923, 0.00105466,\n",
       "       0.00180134])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([     1,      9,     16, ..., 999990, 999992, 999994]),)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([     0,      1,      2, ..., 899997, 899998, 899999])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([540000, 540001, 540002, ..., 719997, 719998, 719999])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<720000x4797415 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 61048607 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<180000x4797415 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 15258775 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's auc: 0.90753\tvalid_1's auc: 0.90588\n",
      "[20]\ttraining's auc: 0.923608\tvalid_1's auc: 0.922226\n",
      "[30]\ttraining's auc: 0.934236\tvalid_1's auc: 0.93271\n",
      "[40]\ttraining's auc: 0.941585\tvalid_1's auc: 0.939866\n",
      "[50]\ttraining's auc: 0.946545\tvalid_1's auc: 0.944722\n",
      "[60]\ttraining's auc: 0.950267\tvalid_1's auc: 0.948282\n",
      "[70]\ttraining's auc: 0.953052\tvalid_1's auc: 0.950938\n",
      "[80]\ttraining's auc: 0.95525\tvalid_1's auc: 0.952965\n",
      "[90]\ttraining's auc: 0.957018\tvalid_1's auc: 0.95462\n",
      "[100]\ttraining's auc: 0.958495\tvalid_1's auc: 0.955982\n",
      "[110]\ttraining's auc: 0.959795\tvalid_1's auc: 0.957151\n",
      "[120]\ttraining's auc: 0.960895\tvalid_1's auc: 0.958102\n",
      "[130]\ttraining's auc: 0.961885\tvalid_1's auc: 0.958905\n",
      "[140]\ttraining's auc: 0.96277\tvalid_1's auc: 0.959651\n",
      "[150]\ttraining's auc: 0.963582\tvalid_1's auc: 0.960299\n",
      "[160]\ttraining's auc: 0.964328\tvalid_1's auc: 0.960891\n",
      "[170]\ttraining's auc: 0.965053\tvalid_1's auc: 0.961401\n",
      "[180]\ttraining's auc: 0.965702\tvalid_1's auc: 0.961882\n",
      "[190]\ttraining's auc: 0.966289\tvalid_1's auc: 0.96231\n",
      "[200]\ttraining's auc: 0.966866\tvalid_1's auc: 0.962725\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.966866\tvalid_1's auc: 0.962725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00979268, 0.79528353, 0.26104046, ..., 0.00508331, 0.00138788,\n",
       "       0.00213625])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([     1,      9,     13, ..., 999992, 999993, 999994]),)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([     0,      1,      2, ..., 719997, 719998, 719999])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([720000, 720001, 720002, ..., 899997, 899998, 899999])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<720000x4797415 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 61046645 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<180000x4797415 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 15260737 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's auc: 0.906804\tvalid_1's auc: 0.906557\n",
      "[20]\ttraining's auc: 0.92273\tvalid_1's auc: 0.921658\n",
      "[30]\ttraining's auc: 0.933957\tvalid_1's auc: 0.932807\n",
      "[40]\ttraining's auc: 0.941481\tvalid_1's auc: 0.940373\n",
      "[50]\ttraining's auc: 0.946573\tvalid_1's auc: 0.945301\n",
      "[60]\ttraining's auc: 0.950208\tvalid_1's auc: 0.948763\n",
      "[70]\ttraining's auc: 0.952912\tvalid_1's auc: 0.951279\n",
      "[80]\ttraining's auc: 0.955106\tvalid_1's auc: 0.95333\n",
      "[90]\ttraining's auc: 0.956925\tvalid_1's auc: 0.954951\n",
      "[100]\ttraining's auc: 0.95843\tvalid_1's auc: 0.956325\n",
      "[110]\ttraining's auc: 0.959697\tvalid_1's auc: 0.957433\n",
      "[120]\ttraining's auc: 0.960791\tvalid_1's auc: 0.958387\n",
      "[130]\ttraining's auc: 0.961792\tvalid_1's auc: 0.959199\n",
      "[140]\ttraining's auc: 0.962662\tvalid_1's auc: 0.959953\n",
      "[150]\ttraining's auc: 0.963461\tvalid_1's auc: 0.96062\n",
      "[160]\ttraining's auc: 0.964222\tvalid_1's auc: 0.961202\n",
      "[170]\ttraining's auc: 0.964912\tvalid_1's auc: 0.961733\n",
      "[180]\ttraining's auc: 0.965539\tvalid_1's auc: 0.962174\n",
      "[190]\ttraining's auc: 0.96614\tvalid_1's auc: 0.962597\n",
      "[200]\ttraining's auc: 0.966745\tvalid_1's auc: 0.962954\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.966745\tvalid_1's auc: 0.962954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.01262285, 0.99449394, 0.32285698, ..., 0.00637901, 0.00173432,\n",
       "       0.00263036])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([     1,      9,     13, ..., 999992, 999993, 999994]),)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.01262285, 0.99449394, 0.32285698, ..., 0.00637901, 0.00173432,\n",
       "       0.00263036])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict gender\n",
    "%reset -f\n",
    "# !pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "print('loading data...')\n",
    "X_train = sparse.load_npz('./train_attr.npz').tocsr()\n",
    "X_predict = sparse.load_npz('./predict_attr.npz').tocsr()\n",
    "y_train = pd.read_csv('./user_info.csv')['gender']\n",
    "print('data is prepared.')\n",
    "\n",
    "predictions = np.zeros(X_predict.shape[0], dtype=float)\n",
    "folds = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "print('start training...')\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    display(trn_idx,val_idx)\n",
    "    trn_data_X_train=X_train[trn_idx,:]\n",
    "    val_data_X_train=X_train[val_idx,:]\n",
    "    display(trn_data_X_train,val_data_X_train)\n",
    "    trn_data = lgb.Dataset(trn_data_X_train, y_train.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(val_data_X_train, y_train.iloc[val_idx])\n",
    "    \n",
    "    lgb_params = {'num_leaves': 2**6-1,\n",
    "              'min_data_in_leaf': 25, \n",
    "              'objective':'binary',\n",
    "              'max_depth': -1,\n",
    "              'learning_rate': 0.1,\n",
    "              'boosting': 'gbdt',\n",
    "              'feature_fraction': 0.6,\n",
    "              'bagging_fraction': 0.9,\n",
    "              'bagging_seed': 11,\n",
    "              'metric': 'auc',\n",
    "              'seed':1024,\n",
    "              'nthread':8,\n",
    "             }\n",
    "    model = lgb.train(lgb_params, \n",
    "                    trn_data,\n",
    "                    num_boost_round=200, \n",
    "                    valid_sets = [trn_data, val_data], \n",
    "                    verbose_eval = 10, \n",
    "                    early_stopping_rounds = 100)\n",
    "    predictions += model.predict(X_predict, num_iteration=model.best_iteration) / folds.n_splits\n",
    "    display(predictions)\n",
    "    display(np.where(predictions>0.5))\n",
    "\n",
    "display(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>predicted_age</th>\n",
       "      <th>predicted_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000002</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000003</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000005</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>3999996</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>3999997</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>3999998</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>3999999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>4000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  predicted_age  predicted_gender\n",
       "0       3000001              0                 1\n",
       "1       3000002              0                 2\n",
       "2       3000003              0                 1\n",
       "3       3000004              0                 1\n",
       "4       3000005              0                 1\n",
       "...         ...            ...               ...\n",
       "999995  3999996              0                 1\n",
       "999996  3999997              0                 1\n",
       "999997  3999998              0                 1\n",
       "999998  3999999              0                 1\n",
       "999999  4000000              0                 1\n",
       "\n",
       "[1000000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission=pd.DataFrame([i for i in range(3000001,4000001)],columns=[\"user_id\"])\n",
    "submission[\"predicted_age\"]=[0 for _ in range(1000000)]\n",
    "submission[\"predicted_gender\"]=(predictions>0.5)*1\n",
    "submission[\"predicted_gender\"]+=1\n",
    "display(submission)\n",
    "submission.describe()\n",
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x4797415 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 36 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict age\n",
    "%reset -f\n",
    "# !pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "print('loading data...')\n",
    "X_train = sparse.load_npz('./train_attr.npz').tocsr()\n",
    "X_predict = sparse.load_npz('./predict_attr.npz').tocsr()\n",
    "y_train = pd.read_csv('./user_info.csv')['age']\n",
    "print('data is prepared.')\n",
    "\n",
    "predictions = np.zeros(X_predict.shape[0], dtype=float)\n",
    "folds = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "print('start training...')\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    display(trn_idx,val_idx)\n",
    "    trn_data_X_train=X_train[trn_idx,:]\n",
    "    val_data_X_train=X_train[val_idx,:]\n",
    "    display(trn_data_X_train,val_data_X_train)\n",
    "    trn_data = lgb.Dataset(trn_data_X_train, y_train.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(val_data_X_train, y_train.iloc[val_idx])\n",
    "    \n",
    "    lgb_params = {'num_leaves': 2**6-1,\n",
    "              'min_data_in_leaf': 25, \n",
    "              'objective':'multiclass',\n",
    "              'max_depth': -1,\n",
    "              'learning_rate': 0.1,\n",
    "              'boosting': 'gbdt',\n",
    "              'feature_fraction': 0.6,\n",
    "              'bagging_fraction': 0.9,\n",
    "              'bagging_seed': 11,\n",
    "              'metric': 'auc',\n",
    "              'seed':1024,\n",
    "              'nthread':8,\n",
    "             }\n",
    "    model = lgb.train(lgb_params, \n",
    "                    trn_data,\n",
    "                    num_boost_round=200, \n",
    "                    valid_sets = [trn_data, val_data], \n",
    "                    verbose_eval = 10, \n",
    "                    early_stopping_rounds = 100)\n",
    "    predictions += model.predict(X_predict, num_iteration=model.best_iteration) / folds.n_splits\n",
    "    display(predictions)\n",
    "\n",
    "display(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "submission = pd.read_csv('./submission.csv')\n",
    "predictions = np.around(predictions)\n",
    "predictions[predictions > 10] = 10\n",
    "predictions[predictions < 1] = 1\n",
    "submission['age'] = predictions\n",
    "submission.to_csv('./submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_py3",
   "language": "python",
   "name": "conda_tensorflow2_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
