{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_ad=pd.read_csv(\"../test/ad.csv\")\n",
    "test_click_log=pd.read_csv(\"../test/click_log.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_merged=pd.read_csv(\"./train_merged.csv\")\n",
    "display(train_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features=[\"creative_id\",\"ad_id\",\"product_id\",\"product_category\",\"advertiser_id\",\"industry\",\"time\",\"click_times\"]\n",
    "targets=[\"age\",\"gender\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmpdf=train_merged.sample(frac=0.1)\n",
    "# tmpdf.info()\n",
    "# display(tmpdf)\n",
    "# tmpdf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%capture cap --no-stderr\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "features=[\"creative_id\",\"ad_id\",\"product_id\",\"product_category\",\"advertiser_id\",\"industry\",\"time\",\"click_times\"]\n",
    "\n",
    "df=train_merged.drop(columns=[\"age\",\"user_id\"])\n",
    "# convert {1,2} to binary value {0,1}\n",
    "df[\"gender\"]-=1\n",
    "# split train data into 2 parts (cross validation)\n",
    "train=df.sample(frac=0.8) #random state is a seed value\n",
    "test=df.drop(train.index)\n",
    "y_train=train.pop(\"gender\")\n",
    "X_train=train\n",
    "y_test=test.pop(\"gender\")\n",
    "X_test=test\n",
    "# display(X_train,y_train)\n",
    "# display(X_test,y_test)\n",
    "\n",
    "\n",
    "train_data = lgb.Dataset(X_train,y_train)\n",
    "train_data.save_binary('train.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "[1]\tcv_agg's auc: 0.655103 + 0.000246757\n",
      "[2]\tcv_agg's auc: 0.664998 + 0.000205661\n",
      "[3]\tcv_agg's auc: 0.668317 + 6.79261e-05\n",
      "[4]\tcv_agg's auc: 0.66964 + 0.000355484\n",
      "[5]\tcv_agg's auc: 0.670757 + 0.000544024\n",
      "[6]\tcv_agg's auc: 0.673907 + 0.000377497\n",
      "[7]\tcv_agg's auc: 0.675651 + 0.000551716\n",
      "[8]\tcv_agg's auc: 0.677268 + 0.000640823\n",
      "[9]\tcv_agg's auc: 0.678158 + 0.000899701\n",
      "[10]\tcv_agg's auc: 0.679363 + 0.000781556\n",
      "[11]\tcv_agg's auc: 0.680395 + 0.000851703\n",
      "[12]\tcv_agg's auc: 0.681316 + 0.00094943\n",
      "[13]\tcv_agg's auc: 0.682439 + 0.000999857\n",
      "[14]\tcv_agg's auc: 0.683199 + 0.000862841\n",
      "[15]\tcv_agg's auc: 0.683822 + 0.000791141\n",
      "[16]\tcv_agg's auc: 0.684391 + 0.000820235\n",
      "[17]\tcv_agg's auc: 0.685201 + 0.000668377\n",
      "[18]\tcv_agg's auc: 0.685958 + 0.000807344\n",
      "[19]\tcv_agg's auc: 0.686751 + 0.000675411\n",
      "[20]\tcv_agg's auc: 0.687396 + 0.000519532\n",
      "[21]\tcv_agg's auc: 0.687939 + 0.000486729\n",
      "[22]\tcv_agg's auc: 0.688583 + 0.000435666\n",
      "[23]\tcv_agg's auc: 0.689327 + 0.000382542\n",
      "[24]\tcv_agg's auc: 0.689912 + 0.000386365\n",
      "[25]\tcv_agg's auc: 0.690482 + 0.000399514\n",
      "[26]\tcv_agg's auc: 0.691228 + 0.000508257\n",
      "[27]\tcv_agg's auc: 0.691789 + 0.000410058\n",
      "[28]\tcv_agg's auc: 0.692326 + 0.000370856\n",
      "[29]\tcv_agg's auc: 0.692872 + 0.000358978\n",
      "[30]\tcv_agg's auc: 0.693443 + 0.000338762\n",
      "[31]\tcv_agg's auc: 0.693945 + 0.000275477\n",
      "[32]\tcv_agg's auc: 0.694293 + 0.000281462\n",
      "[33]\tcv_agg's auc: 0.694738 + 0.000373992\n",
      "[34]\tcv_agg's auc: 0.695246 + 0.000380716\n",
      "[35]\tcv_agg's auc: 0.695697 + 0.000405539\n",
      "[36]\tcv_agg's auc: 0.696222 + 0.000483923\n",
      "[37]\tcv_agg's auc: 0.696794 + 0.000514376\n",
      "[38]\tcv_agg's auc: 0.697391 + 0.00053734\n",
      "[39]\tcv_agg's auc: 0.697806 + 0.000514097\n",
      "[40]\tcv_agg's auc: 0.698338 + 0.000504364\n",
      "[41]\tcv_agg's auc: 0.698823 + 0.000403656\n",
      "[42]\tcv_agg's auc: 0.699295 + 0.000371101\n",
      "[43]\tcv_agg's auc: 0.699671 + 0.000362406\n",
      "[44]\tcv_agg's auc: 0.700088 + 0.000324028\n",
      "[45]\tcv_agg's auc: 0.700507 + 0.000320112\n"
     ]
    }
   ],
   "source": [
    "# %%capture cap --no-stderr\n",
    "%reset -f\n",
    "import lightgbm as lgb\n",
    "train_data = lgb.Dataset('gender.bin')\n",
    "lgb_params = {'num_leaves': 2**6-1,\n",
    "              'min_data_in_leaf': 25, \n",
    "              'objective':'binary',\n",
    "              'max_depth': -1,\n",
    "              'learning_rate': 0.1,\n",
    "              'boosting': 'gbdt',\n",
    "              'feature_fraction': 0.6,\n",
    "              'bagging_fraction': 0.9,\n",
    "              'bagging_seed': 11,\n",
    "              'metric': 'auc',\n",
    "#               'seed':1024,\n",
    "              'nthread':12,\n",
    "             }\n",
    "with open('lgb.md', 'a') as f:\n",
    "    f.write(str(lgb_params))\n",
    "print(\"start training\")\n",
    "cv_results = lgb.cv(\n",
    "    lgb_params, train_data, num_boost_round=1000, nfold=5, stratified=False, shuffle=True,\n",
    "    early_stopping_rounds=50, verbose_eval=1, show_stdv=True, seed=0)\n",
    "# print('best num_boost_round:', len(cv_results['auc-mean']))\n",
    "# print('best cv score:', cv_results['auc-mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('lgb.txt', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "features=[\"creative_id\",\"ad_id\",\"product_id\",\"product_category\",\"advertiser_id\",\"industry\",\"time\",\"click_times\"]\n",
    "\n",
    "df=train_merged.drop(columns=[\"gender\",\"user_id\"])\n",
    "# split train data into 2 parts (cross validation)\n",
    "train=df.sample(frac=0.8) #random state is a seed value\n",
    "test=df.drop(train.index)\n",
    "y_train=train.pop(\"age\")\n",
    "X_train=train\n",
    "y_test=test.pop(\"age\")\n",
    "X_test=test\n",
    "# display(X_train,y_train)\n",
    "# display(X_test,y_test)\n",
    "train_data = lgb.Dataset(X_train,y_train)\n",
    "train_data.save_binary('age.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import lightgbm as lgb\n",
    "train_data = lgb.Dataset('age.bin')\n",
    "params = {'num_leaves': 2**6-1,\n",
    "          'min_data_in_leaf': 25, \n",
    "          'objective':'regression_l2',\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.1,\n",
    "          'min_child_samples': 20,\n",
    "          'boosting': 'gbdt',\n",
    "          'feature_fraction': 0.6,\n",
    "          'bagging_fraction': 0.9,\n",
    "          'bagging_seed': 11,\n",
    "          'metric': 'mae',\n",
    "          'seed':1024,\n",
    "          'lambda_l1': 0.2,\n",
    "          'nthread':12,\n",
    "         }\n",
    "print(\"start training\")\n",
    "cv_results = lgb.cv(\n",
    "    params, train_data, num_boost_round=1000, nfold=5, stratified=False, shuffle=True,\n",
    "    early_stopping_rounds=50, verbose_eval=1, show_stdv=True, seed=0)\n",
    "print('best num_boost_round:', len(cv_results['mae-mean']))\n",
    "print('best cv score:', cv_results['mae-mean'])\n",
    "# bst = lgb.train(param, train_data, num_round,categorical_feature=features)\n",
    "# bst.save_model('test_model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train, y_train, free_raw_data=False)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train,free_raw_data=False)\n",
    "params = {\n",
    "          'boosting_type': 'gbdt',\n",
    "          'objective': 'binary',\n",
    "          'metric': 'auc',\n",
    "          'nthread':12,\n",
    "          'learning_rate':0.1\n",
    "          }\n",
    " \n",
    "### 交叉验证(调参)\n",
    "print('交叉验证')\n",
    "max_auc = float('0')\n",
    "best_params = {}\n",
    " \n",
    "# 准确率\n",
    "print(\"调参1：提高准确率\")\n",
    "for num_leaves in range(5,100,5):\n",
    "    for max_depth in range(3,8,1):\n",
    "        params['num_leaves'] = num_leaves\n",
    "        params['max_depth'] = max_depth\n",
    " \n",
    "        cv_results = lgb.cv(\n",
    "                            params,\n",
    "                            lgb_train,\n",
    "                            seed=1,\n",
    "                            nfold=5,\n",
    "                            metrics=['auc'],\n",
    "                            early_stopping_rounds=10,\n",
    "                            verbose_eval=True\n",
    "                            )\n",
    "            \n",
    "        mean_auc = pd.Series(cv_results['auc-mean']).max()\n",
    "        boost_rounds = pd.Series(cv_results['auc-mean']).idxmax()\n",
    "            \n",
    "        if mean_auc >= max_auc:\n",
    "            max_auc = mean_auc\n",
    "            best_params['num_leaves'] = num_leaves\n",
    "            best_params['max_depth'] = max_depth\n",
    "if 'num_leaves' and 'max_depth' in best_params.keys():          \n",
    "    params['num_leaves'] = best_params['num_leaves']\n",
    "    params['max_depth'] = best_params['max_depth']\n",
    " \n",
    "# 过拟合\n",
    "print(\"调参2：降低过拟合\")\n",
    "for max_bin in range(5,256,10):\n",
    "    for min_data_in_leaf in range(1,102,10):\n",
    "            params['max_bin'] = max_bin\n",
    "            params['min_data_in_leaf'] = min_data_in_leaf\n",
    "            \n",
    "            cv_results = lgb.cv(\n",
    "                                params,\n",
    "                                lgb_train,\n",
    "                                seed=1,\n",
    "                                nfold=5,\n",
    "                                metrics=['auc'],\n",
    "                                early_stopping_rounds=10,\n",
    "                                verbose_eval=True\n",
    "                                )\n",
    "                    \n",
    "            mean_auc = pd.Series(cv_results['auc-mean']).max()\n",
    "            boost_rounds = pd.Series(cv_results['auc-mean']).idxmax()\n",
    " \n",
    "            if mean_auc >= max_auc:\n",
    "                max_auc = mean_auc\n",
    "                best_params['max_bin']= max_bin\n",
    "                best_params['min_data_in_leaf'] = min_data_in_leaf\n",
    "if 'max_bin' and 'min_data_in_leaf' in best_params.keys():\n",
    "    params['min_data_in_leaf'] = best_params['min_data_in_leaf']\n",
    "    params['max_bin'] = best_params['max_bin']\n",
    " \n",
    "print(\"调参3：降低过拟合\")\n",
    "for feature_fraction in [0.6,0.7,0.8,0.9,1.0]:\n",
    "    for bagging_fraction in [0.6,0.7,0.8,0.9,1.0]:\n",
    "        for bagging_freq in range(0,50,5):\n",
    "            params['feature_fraction'] = feature_fraction\n",
    "            params['bagging_fraction'] = bagging_fraction\n",
    "            params['bagging_freq'] = bagging_freq\n",
    "            \n",
    "            cv_results = lgb.cv(\n",
    "                                params,\n",
    "                                lgb_train,\n",
    "                                seed=1,\n",
    "                                nfold=5,\n",
    "                                metrics=['auc'],\n",
    "                                early_stopping_rounds=10,\n",
    "                                verbose_eval=True\n",
    "                                )\n",
    "                    \n",
    "            mean_auc = pd.Series(cv_results['auc-mean']).max()\n",
    "            boost_rounds = pd.Series(cv_results['auc-mean']).idxmax()\n",
    " \n",
    "            if mean_auc >= max_auc:\n",
    "                max_auc=mean_auc\n",
    "                best_params['feature_fraction'] = feature_fraction\n",
    "                best_params['bagging_fraction'] = bagging_fraction\n",
    "                best_params['bagging_freq'] = bagging_freq\n",
    " \n",
    "if 'feature_fraction' and 'bagging_fraction' and 'bagging_freq' in best_params.keys():\n",
    "    params['feature_fraction'] = best_params['feature_fraction']\n",
    "    params['bagging_fraction'] = best_params['bagging_fraction']\n",
    "    params['bagging_freq'] = best_params['bagging_freq']\n",
    " \n",
    " \n",
    "print(\"调参4：降低过拟合\")\n",
    "for lambda_l1 in [1e-5,1e-3,1e-1,0.0,0.1,0.3,0.5,0.7,0.9,1.0]:\n",
    "    for lambda_l2 in [1e-5,1e-3,1e-1,0.0,0.1,0.4,0.6,0.7,0.9,1.0]:\n",
    "        params['lambda_l1'] = lambda_l1\n",
    "        params['lambda_l2'] = lambda_l2\n",
    "        cv_results = lgb.cv(\n",
    "                            params,\n",
    "                            lgb_train,\n",
    "                            seed=1,\n",
    "                            nfold=5,\n",
    "                            metrics=['auc'],\n",
    "                            early_stopping_rounds=10,\n",
    "                            verbose_eval=True\n",
    "                            )\n",
    "                \n",
    "        mean_auc = pd.Series(cv_results['auc-mean']).max()\n",
    "        boost_rounds = pd.Series(cv_results['auc-mean']).idxmax()\n",
    " \n",
    "        if mean_auc >= max_auc:\n",
    "            max_auc=mean_auc\n",
    "            best_params['lambda_l1'] = lambda_l1\n",
    "            best_params['lambda_l2'] = lambda_l2\n",
    "if 'lambda_l1' and 'lambda_l2' in best_params.keys():\n",
    "    params['lambda_l1'] = best_params['lambda_l1']\n",
    "    params['lambda_l2'] = best_params['lambda_l2']\n",
    " \n",
    "print(\"调参5：降低过拟合2\")\n",
    "for min_split_gain in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "    params['min_split_gain'] = min_split_gain\n",
    "    \n",
    "    cv_results = lgb.cv(\n",
    "                        params,\n",
    "                        lgb_train,\n",
    "                        seed=1,\n",
    "                        nfold=5,\n",
    "                        metrics=['auc'],\n",
    "                        early_stopping_rounds=10,\n",
    "                        verbose_eval=True\n",
    "                        )\n",
    "            \n",
    "    mean_auc = pd.Series(cv_results['auc-mean']).max()\n",
    "    boost_rounds = pd.Series(cv_results['auc-mean']).idxmax()\n",
    " \n",
    "    if mean_auc >= max_auc:\n",
    "        max_auc=mean_auc\n",
    "        \n",
    "        best_params['min_split_gain'] = min_split_gain\n",
    "if 'min_split_gain' in best_params.keys():\n",
    "    params['min_split_gain'] = best_params['min_split_gain']\n",
    " \n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "df=tmpdf\n",
    "features=[\"creative_id\"]\n",
    "v = TfidfVectorizer(max_df=1.0,min_df=1,lowercase=False,tokenizer=lambda x:x)\n",
    "for feature in features:\n",
    "    cur=df.groupby(\"user_id\")[feature].apply(list)\n",
    "    v_fit = v.fit_transform(cur)\n",
    "    word=v.get_feature_names()\n",
    "    display(v_fit)\n",
    "    display(type(v_fit))\n",
    "#     for i in range(len(weight)):\n",
    "#         print(\"-----output feature={}, user_id={} tf-idf-----\".format(feature,i+1))\n",
    "#         for j in range(len(word)):\n",
    "#             print(word[j],weight[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_py3",
   "language": "python",
   "name": "conda_tensorflow2_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
